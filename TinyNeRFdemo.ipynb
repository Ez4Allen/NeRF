{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6af9a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, time\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_blender_data_raw(basedir):\n",
    "    splits = ['train', 'val', 'test']\n",
    "    metas = {s: json.load(open(os.path.join(basedir, f\"transforms_{s}.json\"), \"r\"))\n",
    "             for s in splits}\n",
    "\n",
    "    all_imgs, all_poses, counts = [], [], [0]\n",
    "    for s in splits:\n",
    "        meta = metas[s]\n",
    "        imgs, poses = [], []\n",
    "        for f in meta[\"frames\"]:\n",
    "            fname = os.path.join(basedir, f[\"file_path\"] + \".png\")\n",
    "            imgs.append(imageio.imread(fname).astype(np.float32) / 255.0)\n",
    "            poses.append(np.array(f[\"transform_matrix\"], dtype=np.float32))\n",
    "        imgs  = np.stack(imgs,  axis=0)\n",
    "        poses = np.stack(poses, axis=0)\n",
    "        counts.append(counts[-1] + imgs.shape[0])\n",
    "        all_imgs.append(imgs)\n",
    "        all_poses.append(poses)\n",
    "\n",
    "    imgs  = np.concatenate(all_imgs,  axis=0)\n",
    "    poses = np.concatenate(all_poses, axis=0)\n",
    "\n",
    "    H, W = imgs[0].shape[:2]\n",
    "    camera_angle_x = float(metas[\"train\"][\"camera_angle_x\"])\n",
    "    focal = 0.5 * W / np.tan(0.5 * camera_angle_x)\n",
    "    i_split = [np.arange(counts[i], counts[i+1]) for i in range(3)]\n",
    "    return imgs, poses, [H, W, focal], i_split\n",
    "\n",
    "\n",
    "def get_rays(H, W, focal, c2w):\n",
    "    device = c2w.device\n",
    "    i, j = torch.meshgrid(\n",
    "        torch.arange(W, dtype=torch.float32, device=device),\n",
    "        torch.arange(H, dtype=torch.float32, device=device),\n",
    "        indexing=\"xy\"\n",
    "    )\n",
    "    dirs = torch.stack([\n",
    "        (i - W * 0.5) / focal,\n",
    "        -(j - H * 0.5) / focal,\n",
    "        -torch.ones_like(i)\n",
    "    ], dim=-1)\n",
    "\n",
    "    R = c2w[:3, :3]\n",
    "    t = c2w[:3, 3]\n",
    "    rd = dirs @ R.T\n",
    "    rd = F.normalize(rd, dim=-1)\n",
    "    ro = t.expand_as(rd)\n",
    "    return ro, rd\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def build_ray_bank(imgs, poses, H, W, focal):\n",
    "    N = imgs.shape[0]\n",
    "    rays_o, rays_d = [], []\n",
    "    for n in range(N):\n",
    "        ro, rd = get_rays(H, W, focal, poses[n])\n",
    "        rays_o.append(ro)\n",
    "        rays_d.append(rd)\n",
    "    rays_o = torch.stack(rays_o, 0).reshape(-1, 3)\n",
    "    rays_d = torch.stack(rays_d, 0).reshape(-1, 3)\n",
    "    rgb = imgs[..., :3].reshape(-1, 3)\n",
    "    return rays_o, rays_d, rgb\n",
    "\n",
    "\n",
    "def sample_along_rays(rays_o, rays_d, near, far, S=64, stratified=True):\n",
    "    B = rays_o.shape[0]\n",
    "    z_lin = torch.linspace(0., 1., S, device=rays_o.device)\n",
    "    z = near * (1. - z_lin) + far * z_lin\n",
    "    z = z.unsqueeze(0).expand(B, S)\n",
    "\n",
    "    if stratified:\n",
    "        mids = 0.5 * (z[:, :-1] + z[:, 1:])\n",
    "        lows = torch.cat([z[:, :1], mids], dim=1)\n",
    "        highs = torch.cat([mids, z[:, -1:]], dim=1)\n",
    "        z = lows + (highs - lows) * torch.rand_like(z)\n",
    "\n",
    "    pts = rays_o[:, None, :] + rays_d[:, None, :] * z[..., None]\n",
    "    return z, pts\n",
    "\n",
    "\n",
    "def volume_render(rgb, sigma, z, rays_d, white_bkgd=True):\n",
    "    B, S, _ = rgb.shape\n",
    "    deltas = (z[:, 1:] - z[:, :-1])\n",
    "    deltas = torch.cat([deltas, torch.full((B, 1), 1e10, device=z.device)], dim=1)[..., None]\n",
    "\n",
    "    dist = deltas * torch.linalg.norm(rays_d, dim=-1, keepdim=True).unsqueeze(1)\n",
    "    alpha = 1. - torch.exp(-sigma * dist)\n",
    "\n",
    "    T = torch.cumprod(torch.cat(\n",
    "        [torch.ones(B, 1, 1, device=z.device), 1. - alpha + 1e-10], dim=1\n",
    "    ), dim=1)[:, :-1]\n",
    "\n",
    "    weights = alpha * T\n",
    "    rgb_map = torch.sum(weights * rgb, dim=1)\n",
    "    acc_map = torch.sum(weights, dim=1)\n",
    "\n",
    "    if white_bkgd:\n",
    "        rgb_map = rgb_map + (1. - acc_map)\n",
    "\n",
    "    return rgb_map, acc_map, weights\n",
    "\n",
    "\n",
    "def sample_pdf(bins, weights, N_importance, deterministic=False, eps=1e-5):\n",
    "    weights = weights + eps\n",
    "    pdf = weights / torch.sum(weights, dim=-1, keepdim=True)\n",
    "    cdf = torch.cumsum(pdf, dim=-1)\n",
    "    cdf = torch.cat([torch.zeros_like(cdf[..., :1]), cdf], dim=-1)\n",
    "\n",
    "    if deterministic:\n",
    "        u = torch.linspace(0., 1., N_importance, device=bins.device)\n",
    "        u = u.unsqueeze(0).expand(bins.shape[0], N_importance)\n",
    "    else:\n",
    "        u = torch.rand(bins.shape[0], N_importance, device=bins.device)\n",
    "\n",
    "    inds = torch.searchsorted(cdf, u, right=True)\n",
    "    below = torch.clamp(inds - 1, min=0)\n",
    "    above = torch.clamp(inds, max=cdf.shape[-1] - 1)\n",
    "\n",
    "    cdf_b = torch.gather(cdf, 1, below)\n",
    "    cdf_a = torch.gather(cdf, 1, above)\n",
    "    bins_b = torch.gather(bins, 1, torch.clamp(below - 1, min=0))\n",
    "    bins_a = torch.gather(bins, 1, torch.clamp(above - 1, min=0))\n",
    "\n",
    "    denom = (cdf_a - cdf_b).clamp_min(eps)\n",
    "    t = (u - cdf_b) / denom\n",
    "    return bins_b + t * (bins_a - bins_b)\n",
    "\n",
    "\n",
    "class PosEnc(nn.Module):\n",
    "    def __init__(self, num_freqs):\n",
    "        super().__init__()\n",
    "        self.num_freqs = num_freqs\n",
    "        self.register_buffer(\"freq_bands\", (2. ** torch.arange(num_freqs).float()) * math.pi)\n",
    "        self.register_buffer(\"freq_weights\", torch.ones(num_freqs))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def set_window_by_iter(self, step, end_step):\n",
    "        if end_step is None or end_step <= 0:\n",
    "            w = torch.ones(self.num_freqs, device=self.freq_weights.device)\n",
    "        else:\n",
    "            p = max(0.0, min(1.0, float(step) / float(end_step)))\n",
    "            k = torch.arange(self.num_freqs, device=self.freq_weights.device).float()\n",
    "            w = (p * self.num_freqs - k).clamp_(0.0, 1.0)\n",
    "        self.freq_weights.copy_(w)\n",
    "\n",
    "    def forward(self, x):\n",
    "        freqs = self.freq_bands.to(x.device)\n",
    "        xb = x[..., None, :] * freqs[:, None]\n",
    "        s = torch.sin(xb)\n",
    "        c = torch.cos(xb)\n",
    "        w = self.freq_weights.to(x.device)[:, None]\n",
    "        s = s * w\n",
    "        c = c * w\n",
    "        enc = torch.cat([s, c], dim=-1)\n",
    "        return enc.view(*x.shape[:-1], -1)\n",
    "\n",
    "\n",
    "class TinyNeRF_PE(nn.Module):\n",
    "    def __init__(self, Lx=10, Ld=4, hidden=256):\n",
    "        super().__init__()\n",
    "        in_xyz = 3 + 3 * 2 * Lx\n",
    "        in_dir = 3 * 2 * Ld\n",
    "\n",
    "        self.pe_xyz = PosEnc(Lx)\n",
    "        self.pe_dir = PosEnc(Ld)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_xyz, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.fc3 = nn.Linear(hidden, hidden)\n",
    "        self.fc4 = nn.Linear(hidden + in_xyz, hidden)\n",
    "\n",
    "        self.fc_sigma = nn.Linear(hidden, 1)\n",
    "        self.fc_feat  = nn.Linear(hidden, hidden)\n",
    "\n",
    "        self.fc_dir = nn.Linear(hidden + in_dir, hidden // 2)\n",
    "        self.fc_rgb = nn.Linear(hidden // 2, 3)\n",
    "\n",
    "    def forward(self, pts, dirs=None):\n",
    "        pe_xyz = self.pe_xyz(pts)\n",
    "        x_in = torch.cat([pts, pe_xyz], dim=-1)\n",
    "\n",
    "        h = F.relu(self.fc1(x_in))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        h = F.relu(self.fc3(h))\n",
    "        h = torch.cat([h, x_in], dim=-1)\n",
    "        h = F.relu(self.fc4(h))\n",
    "\n",
    "        sigma = F.softplus(self.fc_sigma(h))\n",
    "        feat  = F.relu(self.fc_feat(h))\n",
    "\n",
    "        if dirs is not None:\n",
    "            pe_d = self.pe_dir(dirs)\n",
    "            h_col = torch.cat([feat, pe_d], dim=-1)\n",
    "        else:\n",
    "            h_col = feat\n",
    "\n",
    "        h_col = F.relu(self.fc_dir(h_col))\n",
    "        rgb = torch.sigmoid(self.fc_rgb(h_col))\n",
    "\n",
    "        return rgb, sigma\n",
    "\n",
    "\n",
    "def mse2psnr(x):\n",
    "    return -10.0 * torch.log10(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f156d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     1  L=0.216700  PSNR_f=7.06  PSNR_c=7.06  [pos=0/10, dir=0/4]  (0.2s)\n",
      "Iter     2  L=0.217752  PSNR_f=7.03  PSNR_c=7.03  [pos=0/10, dir=0/4]  (0.1s)\n",
      "Iter     3  L=0.209801  PSNR_f=7.20  PSNR_c=7.20  [pos=0/10, dir=0/4]  (0.1s)\n",
      "Iter     4  L=0.215056  PSNR_f=7.09  PSNR_c=7.09  [pos=0/10, dir=0/4]  (0.1s)\n",
      "Iter     5  L=0.208091  PSNR_f=7.23  PSNR_c=7.23  [pos=0/10, dir=0/4]  (0.1s)\n",
      "Iter     6  L=0.206412  PSNR_f=7.27  PSNR_c=7.27  [pos=0/10, dir=0/4]  (0.1s)\n",
      "Iter     7  L=0.208828  PSNR_f=7.22  PSNR_c=7.22  [pos=0/10, dir=0/4]  (0.1s)\n",
      "Iter     8  L=0.201330  PSNR_f=7.37  PSNR_c=7.38  [pos=0/10, dir=0/4]  (0.1s)\n",
      "Iter     9  L=0.198896  PSNR_f=7.43  PSNR_c=7.43  [pos=0/10, dir=0/4]  (0.1s)\n",
      "Iter    10  L=0.199033  PSNR_f=7.42  PSNR_c=7.43  [pos=0/10, dir=0/4]  (0.1s)\n",
      "Iter    50  L=0.093318  PSNR_f=10.71  PSNR_c=10.71  [pos=0/10, dir=0/4]  (3.0s)\n",
      "Iter   100  L=0.058600  PSNR_f=12.74  PSNR_c=12.73  [pos=0/10, dir=0/4]  (3.8s)\n",
      "[TEST] iter   100 | fine: L=0.163508, PSNR=7.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\77980\\AppData\\Local\\Temp\\ipykernel_8960\\3200093119.py:125: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at C:/actions-runner/_work/pytorch/pytorch/builder/windows/pytorch/aten/src\\ATen/native/BucketizationUtils.h:34.)\n",
      "  inds = torch.searchsorted(cdf, u, right=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   150  L=0.039333  PSNR_f=14.47  PSNR_c=14.46  [pos=0/10, dir=0/4]  (3.8s)\n",
      "Iter   200  L=0.026927  PSNR_f=16.11  PSNR_c=16.13  [pos=0/10, dir=0/4]  (3.8s)\n",
      "[TEST] iter   200 | fine: L=0.073858, PSNR=11.32\n",
      "Iter   250  L=0.023049  PSNR_f=16.79  PSNR_c=16.76  [pos=0/10, dir=0/4]  (3.8s)\n",
      "Iter   300  L=0.020590  PSNR_f=17.28  PSNR_c=17.22  [pos=0/10, dir=0/4]  (3.8s)\n",
      "[TEST] iter   300 | fine: L=0.057830, PSNR=12.38\n",
      "Iter   350  L=0.019808  PSNR_f=17.45  PSNR_c=17.36  [pos=0/10, dir=0/4]  (3.8s)\n",
      "Iter   400  L=0.017669  PSNR_f=17.95  PSNR_c=17.84  [pos=0/10, dir=0/4]  (3.8s)\n",
      "[TEST] iter   400 | fine: L=0.049355, PSNR=13.07\n",
      "Iter   450  L=0.016744  PSNR_f=18.19  PSNR_c=18.08  [pos=0/10, dir=0/4]  (3.8s)\n",
      "Iter   500  L=0.016151  PSNR_f=18.35  PSNR_c=18.17  [pos=0/10, dir=0/4]  (3.8s)\n",
      "[TEST] iter   500 | fine: L=0.046167, PSNR=13.36\n",
      "Iter   550  L=0.015645  PSNR_f=18.47  PSNR_c=18.42  [pos=0/10, dir=0/4]  (3.8s)\n",
      "Iter   600  L=0.014951  PSNR_f=18.68  PSNR_c=18.58  [pos=0/10, dir=0/4]  (3.8s)\n",
      "[TEST] iter   600 | fine: L=0.041345, PSNR=13.84\n",
      "Iter   650  L=0.015033  PSNR_f=18.65  PSNR_c=18.54  [pos=0/10, dir=0/4]  (3.8s)\n",
      "Iter   700  L=0.013127  PSNR_f=19.23  PSNR_c=19.23  [pos=0/10, dir=0/4]  (3.8s)\n",
      "[TEST] iter   700 | fine: L=0.042964, PSNR=13.67\n",
      "Iter   750  L=0.014334  PSNR_f=18.88  PSNR_c=18.57  [pos=0/10, dir=0/4]  (3.8s)\n",
      "Iter   800  L=0.012742  PSNR_f=19.38  PSNR_c=19.16  [pos=1/10, dir=0/4]  (3.8s)\n",
      "[TEST] iter   800 | fine: L=0.036391, PSNR=14.39\n",
      "Iter   850  L=0.012884  PSNR_f=19.32  PSNR_c=19.24  [pos=1/10, dir=0/4]  (3.8s)\n",
      "Iter   900  L=0.012740  PSNR_f=19.40  PSNR_c=19.03  [pos=1/10, dir=0/4]  (3.8s)\n",
      "[TEST] iter   900 | fine: L=0.037963, PSNR=14.21\n",
      "Iter   950  L=0.011530  PSNR_f=19.82  PSNR_c=19.57  [pos=1/10, dir=0/4]  (3.9s)\n",
      "Iter  1000  L=0.014079  PSNR_f=18.95  PSNR_c=18.72  [pos=1/10, dir=1/4]  (3.8s)\n",
      "[TEST] iter  1000 | fine: L=0.037201, PSNR=14.29\n",
      "Iter  1050  L=0.012480  PSNR_f=19.48  PSNR_c=19.19  [pos=1/10, dir=1/4]  (3.9s)\n",
      "Iter  1100  L=0.012119  PSNR_f=19.60  PSNR_c=19.33  [pos=1/10, dir=1/4]  (3.8s)\n",
      "[TEST] iter  1100 | fine: L=0.035732, PSNR=14.47\n",
      "Iter  1150  L=0.012410  PSNR_f=19.48  PSNR_c=19.40  [pos=1/10, dir=1/4]  (3.8s)\n",
      "Iter  1200  L=0.012167  PSNR_f=19.57  PSNR_c=19.44  [pos=1/10, dir=1/4]  (3.8s)\n",
      "[TEST] iter  1200 | fine: L=0.034212, PSNR=14.66\n",
      "Iter  1250  L=0.011686  PSNR_f=19.74  PSNR_c=19.66  [pos=1/10, dir=1/4]  (3.8s)\n",
      "Iter  1300  L=0.010246  PSNR_f=20.34  PSNR_c=19.98  [pos=1/10, dir=1/4]  (3.8s)\n",
      "[TEST] iter  1300 | fine: L=0.033805, PSNR=14.71\n",
      "Iter  1350  L=0.011269  PSNR_f=19.92  PSNR_c=19.68  [pos=1/10, dir=1/4]  (3.8s)\n",
      "Iter  1400  L=0.011701  PSNR_f=19.76  PSNR_c=19.48  [pos=1/10, dir=1/4]  (3.8s)\n",
      "[TEST] iter  1400 | fine: L=0.032629, PSNR=14.86\n",
      "Iter  1450  L=0.011463  PSNR_f=19.84  PSNR_c=19.68  [pos=1/10, dir=1/4]  (3.8s)\n",
      "Iter  1500  L=0.011295  PSNR_f=19.92  PSNR_c=19.53  [pos=1/10, dir=1/4]  (3.8s)\n",
      "[TEST] iter  1500 | fine: L=0.031889, PSNR=14.96\n",
      "Iter  1550  L=0.010780  PSNR_f=20.12  PSNR_c=19.82  [pos=1/10, dir=1/4]  (3.8s)\n",
      "Iter  1600  L=0.010193  PSNR_f=20.36  PSNR_c=20.05  [pos=2/10, dir=1/4]  (3.8s)\n",
      "[TEST] iter  1600 | fine: L=0.032303, PSNR=14.91\n",
      "Iter  1650  L=0.011640  PSNR_f=19.77  PSNR_c=19.59  [pos=2/10, dir=1/4]  (3.8s)\n",
      "Iter  1700  L=0.011136  PSNR_f=19.97  PSNR_c=19.77  [pos=2/10, dir=1/4]  (3.8s)\n",
      "[TEST] iter  1700 | fine: L=0.031640, PSNR=15.00\n",
      "Iter  1750  L=0.010912  PSNR_f=20.04  PSNR_c=19.95  [pos=2/10, dir=1/4]  (3.8s)\n",
      "Iter  1800  L=0.010679  PSNR_f=20.16  PSNR_c=19.79  [pos=2/10, dir=1/4]  (3.8s)\n",
      "[TEST] iter  1800 | fine: L=0.030111, PSNR=15.21\n",
      "Iter  1850  L=0.010414  PSNR_f=20.25  PSNR_c=20.09  [pos=2/10, dir=1/4]  (3.8s)\n",
      "Iter  1900  L=0.010873  PSNR_f=20.08  PSNR_c=19.74  [pos=2/10, dir=1/4]  (3.8s)\n",
      "[TEST] iter  1900 | fine: L=0.029118, PSNR=15.36\n",
      "Iter  1950  L=0.009835  PSNR_f=20.55  PSNR_c=19.91  [pos=2/10, dir=1/4]  (3.8s)\n",
      "Iter  2000  L=0.010367  PSNR_f=20.31  PSNR_c=19.77  [pos=2/10, dir=2/4]  (3.8s)\n",
      "[TEST] iter  2000 | fine: L=0.028190, PSNR=15.50\n",
      "Iter  2050  L=0.009231  PSNR_f=20.79  PSNR_c=20.51  [pos=2/10, dir=2/4]  (3.8s)\n",
      "Iter  2100  L=0.009350  PSNR_f=20.76  PSNR_c=20.16  [pos=2/10, dir=2/4]  (3.8s)\n",
      "[TEST] iter  2100 | fine: L=0.026726, PSNR=15.73\n",
      "Iter  2150  L=0.009600  PSNR_f=20.63  PSNR_c=20.26  [pos=2/10, dir=2/4]  (3.8s)\n",
      "Iter  2200  L=0.009989  PSNR_f=20.45  PSNR_c=20.12  [pos=2/10, dir=2/4]  (3.8s)\n",
      "[TEST] iter  2200 | fine: L=0.025444, PSNR=15.94\n",
      "Iter  2250  L=0.007858  PSNR_f=21.51  PSNR_c=21.02  [pos=2/10, dir=2/4]  (3.8s)\n",
      "Iter  2300  L=0.009996  PSNR_f=20.45  PSNR_c=20.10  [pos=2/10, dir=2/4]  (3.8s)\n",
      "[TEST] iter  2300 | fine: L=0.024315, PSNR=16.14\n",
      "Iter  2350  L=0.008163  PSNR_f=21.32  PSNR_c=21.09  [pos=2/10, dir=2/4]  (3.8s)\n",
      "Iter  2400  L=0.009278  PSNR_f=20.81  PSNR_c=20.09  [pos=3/10, dir=2/4]  (3.8s)\n",
      "[TEST] iter  2400 | fine: L=0.024758, PSNR=16.06\n",
      "Iter  2450  L=0.007559  PSNR_f=21.64  PSNR_c=21.49  [pos=3/10, dir=2/4]  (3.8s)\n",
      "Iter  2500  L=0.008512  PSNR_f=21.18  PSNR_c=20.50  [pos=3/10, dir=2/4]  (3.8s)\n",
      "[TEST] iter  2500 | fine: L=0.025044, PSNR=16.01\n",
      "Iter  2550  L=0.010156  PSNR_f=20.39  PSNR_c=19.96  [pos=3/10, dir=2/4]  (3.8s)\n",
      "Iter  2600  L=0.009219  PSNR_f=20.81  PSNR_c=20.33  [pos=3/10, dir=2/4]  (3.8s)\n",
      "[TEST] iter  2600 | fine: L=0.023596, PSNR=16.27\n",
      "Iter  2650  L=0.008443  PSNR_f=21.18  PSNR_c=20.89  [pos=3/10, dir=2/4]  (3.8s)\n",
      "Iter  2700  L=0.007598  PSNR_f=21.67  PSNR_c=21.05  [pos=3/10, dir=2/4]  (3.8s)\n",
      "[TEST] iter  2700 | fine: L=0.022560, PSNR=16.47\n",
      "Iter  2750  L=0.008164  PSNR_f=21.33  PSNR_c=20.98  [pos=3/10, dir=2/4]  (3.8s)\n",
      "Iter  2800  L=0.007859  PSNR_f=21.51  PSNR_c=21.03  [pos=3/10, dir=2/4]  (3.8s)\n",
      "[TEST] iter  2800 | fine: L=0.021021, PSNR=16.77\n",
      "Iter  2850  L=0.008116  PSNR_f=21.35  PSNR_c=21.00  [pos=3/10, dir=2/4]  (3.8s)\n",
      "Iter  2900  L=0.007847  PSNR_f=21.52  PSNR_c=20.99  [pos=3/10, dir=2/4]  (3.8s)\n",
      "[TEST] iter  2900 | fine: L=0.020146, PSNR=16.96\n",
      "Iter  2950  L=0.008478  PSNR_f=21.15  PSNR_c=20.94  [pos=3/10, dir=2/4]  (3.8s)\n",
      "Iter  3000  L=0.007311  PSNR_f=21.89  PSNR_c=20.78  [pos=3/10, dir=3/4]  (3.8s)\n",
      "[TEST] iter  3000 | fine: L=0.019292, PSNR=17.15\n",
      "Iter  3050  L=0.007540  PSNR_f=21.69  PSNR_c=21.18  [pos=3/10, dir=3/4]  (3.8s)\n",
      "Iter  3100  L=0.007286  PSNR_f=21.87  PSNR_c=21.02  [pos=3/10, dir=3/4]  (3.8s)\n",
      "[TEST] iter  3100 | fine: L=0.019233, PSNR=17.16\n",
      "Iter  3150  L=0.006151  PSNR_f=22.59  PSNR_c=21.93  [pos=3/10, dir=3/4]  (3.8s)\n",
      "Iter  3200  L=0.005980  PSNR_f=22.71  PSNR_c=22.07  [pos=4/10, dir=3/4]  (3.8s)\n",
      "[TEST] iter  3200 | fine: L=0.017549, PSNR=17.56\n",
      "Iter  3250  L=0.007380  PSNR_f=21.80  PSNR_c=21.16  [pos=4/10, dir=3/4]  (3.8s)\n",
      "Iter  3300  L=0.007204  PSNR_f=21.87  PSNR_c=21.58  [pos=4/10, dir=3/4]  (3.8s)\n",
      "[TEST] iter  3300 | fine: L=0.019260, PSNR=17.15\n",
      "Iter  3350  L=0.006418  PSNR_f=22.42  PSNR_c=21.58  [pos=4/10, dir=3/4]  (3.8s)\n",
      "Iter  3400  L=0.006007  PSNR_f=22.71  PSNR_c=21.91  [pos=4/10, dir=3/4]  (3.8s)\n",
      "[TEST] iter  3400 | fine: L=0.016304, PSNR=17.88\n",
      "Iter  3450  L=0.006178  PSNR_f=22.53  PSNR_c=22.24  [pos=4/10, dir=3/4]  (3.8s)\n",
      "Iter  3500  L=0.007243  PSNR_f=21.87  PSNR_c=21.29  [pos=4/10, dir=3/4]  (3.8s)\n",
      "[TEST] iter  3500 | fine: L=0.016226, PSNR=17.90\n",
      "Iter  3550  L=0.007043  PSNR_f=22.03  PSNR_c=21.08  [pos=4/10, dir=3/4]  (3.9s)\n",
      "Iter  3600  L=0.007015  PSNR_f=22.02  PSNR_c=21.32  [pos=4/10, dir=3/4]  (3.9s)\n",
      "[TEST] iter  3600 | fine: L=0.016405, PSNR=17.85\n",
      "Iter  3650  L=0.006025  PSNR_f=22.67  PSNR_c=22.13  [pos=4/10, dir=3/4]  (3.9s)\n",
      "Iter  3700  L=0.005799  PSNR_f=22.91  PSNR_c=21.63  [pos=4/10, dir=3/4]  (3.9s)\n",
      "[TEST] iter  3700 | fine: L=0.017511, PSNR=17.57\n",
      "Iter  3750  L=0.006892  PSNR_f=22.13  PSNR_c=21.17  [pos=4/10, dir=3/4]  (3.9s)\n",
      "Iter  3800  L=0.007181  PSNR_f=21.93  PSNR_c=21.17  [pos=4/10, dir=3/4]  (3.9s)\n",
      "[TEST] iter  3800 | fine: L=0.016426, PSNR=17.84\n",
      "Iter  3850  L=0.007409  PSNR_f=21.79  PSNR_c=21.02  [pos=4/10, dir=3/4]  (4.0s)\n",
      "Iter  3900  L=0.006572  PSNR_f=22.31  PSNR_c=21.57  [pos=4/10, dir=3/4]  (3.8s)\n",
      "[TEST] iter  3900 | fine: L=0.017186, PSNR=17.65\n",
      "Iter  3950  L=0.006293  PSNR_f=22.53  PSNR_c=21.49  [pos=4/10, dir=3/4]  (3.9s)\n",
      "Iter  4000  L=0.005461  PSNR_f=23.13  PSNR_c=22.22  [pos=5/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  4000 | fine: L=0.016815, PSNR=17.74\n",
      "Iter  4050  L=0.006105  PSNR_f=22.67  PSNR_c=21.60  [pos=5/10, dir=4/4]  (4.0s)\n",
      "Iter  4100  L=0.006754  PSNR_f=22.18  PSNR_c=21.58  [pos=5/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  4100 | fine: L=0.016159, PSNR=17.92\n",
      "Iter  4150  L=0.006506  PSNR_f=22.41  PSNR_c=21.18  [pos=5/10, dir=4/4]  (4.0s)\n",
      "Iter  4200  L=0.006054  PSNR_f=22.75  PSNR_c=21.30  [pos=5/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  4200 | fine: L=0.015108, PSNR=18.21\n",
      "Iter  4250  L=0.005740  PSNR_f=22.93  PSNR_c=21.87  [pos=5/10, dir=4/4]  (4.0s)\n",
      "Iter  4300  L=0.005354  PSNR_f=23.27  PSNR_c=21.93  [pos=5/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  4300 | fine: L=0.015523, PSNR=18.09\n",
      "Iter  4350  L=0.005653  PSNR_f=22.96  PSNR_c=22.25  [pos=5/10, dir=4/4]  (3.9s)\n",
      "Iter  4400  L=0.006634  PSNR_f=22.34  PSNR_c=20.98  [pos=5/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  4400 | fine: L=0.014481, PSNR=18.39\n",
      "Iter  4450  L=0.005531  PSNR_f=23.07  PSNR_c=22.23  [pos=5/10, dir=4/4]  (3.9s)\n",
      "Iter  4500  L=0.005486  PSNR_f=23.13  PSNR_c=22.07  [pos=5/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  4500 | fine: L=0.014896, PSNR=18.27\n",
      "Iter  4550  L=0.005813  PSNR_f=22.86  PSNR_c=21.97  [pos=5/10, dir=4/4]  (3.9s)\n",
      "Iter  4600  L=0.005508  PSNR_f=23.13  PSNR_c=21.93  [pos=5/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  4600 | fine: L=0.014864, PSNR=18.28\n",
      "Iter  4650  L=0.006905  PSNR_f=22.09  PSNR_c=21.39  [pos=5/10, dir=4/4]  (3.8s)\n",
      "Iter  4700  L=0.006407  PSNR_f=22.50  PSNR_c=21.04  [pos=5/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  4700 | fine: L=0.014274, PSNR=18.45\n",
      "Iter  4750  L=0.005420  PSNR_f=23.20  PSNR_c=21.97  [pos=5/10, dir=4/4]  (3.9s)\n",
      "Iter  4800  L=0.006230  PSNR_f=22.60  PSNR_c=21.31  [pos=6/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  4800 | fine: L=0.013783, PSNR=18.61\n",
      "Iter  4850  L=0.006597  PSNR_f=22.32  PSNR_c=21.29  [pos=6/10, dir=4/4]  (3.8s)\n",
      "Iter  4900  L=0.005651  PSNR_f=22.99  PSNR_c=22.01  [pos=6/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  4900 | fine: L=0.015618, PSNR=18.06\n",
      "Iter  4950  L=0.006798  PSNR_f=22.18  PSNR_c=21.30  [pos=6/10, dir=4/4]  (3.8s)\n",
      "Iter  5000  L=0.005270  PSNR_f=23.35  PSNR_c=21.87  [pos=6/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  5000 | fine: L=0.014237, PSNR=18.47\n",
      "Iter  5050  L=0.004993  PSNR_f=23.54  PSNR_c=22.49  [pos=6/10, dir=4/4]  (3.8s)\n",
      "Iter  5100  L=0.005472  PSNR_f=23.18  PSNR_c=21.80  [pos=6/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  5100 | fine: L=0.014757, PSNR=18.31\n",
      "Iter  5150  L=0.006428  PSNR_f=22.51  PSNR_c=20.85  [pos=6/10, dir=4/4]  (3.8s)\n",
      "Iter  5200  L=0.005884  PSNR_f=22.86  PSNR_c=21.47  [pos=6/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  5200 | fine: L=0.014411, PSNR=18.41\n",
      "Iter  5250  L=0.006251  PSNR_f=22.57  PSNR_c=21.43  [pos=6/10, dir=4/4]  (3.9s)\n",
      "Iter  5300  L=0.005693  PSNR_f=23.04  PSNR_c=21.38  [pos=6/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  5300 | fine: L=0.014459, PSNR=18.40\n",
      "Iter  5350  L=0.005274  PSNR_f=23.36  PSNR_c=21.78  [pos=6/10, dir=4/4]  (3.8s)\n",
      "Iter  5400  L=0.005811  PSNR_f=22.93  PSNR_c=21.45  [pos=6/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  5400 | fine: L=0.014925, PSNR=18.26\n",
      "Iter  5450  L=0.006183  PSNR_f=22.65  PSNR_c=21.28  [pos=6/10, dir=4/4]  (3.8s)\n",
      "Iter  5500  L=0.005762  PSNR_f=22.97  PSNR_c=21.44  [pos=6/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  5500 | fine: L=0.014921, PSNR=18.26\n",
      "Iter  5550  L=0.005376  PSNR_f=23.28  PSNR_c=21.71  [pos=6/10, dir=4/4]  (3.8s)\n",
      "Iter  5600  L=0.004680  PSNR_f=23.83  PSNR_c=22.67  [pos=7/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  5600 | fine: L=0.014664, PSNR=18.34\n",
      "Iter  5650  L=0.005554  PSNR_f=23.14  PSNR_c=21.55  [pos=7/10, dir=4/4]  (3.8s)\n",
      "Iter  5700  L=0.006008  PSNR_f=22.73  PSNR_c=21.73  [pos=7/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  5700 | fine: L=0.014410, PSNR=18.41\n",
      "Iter  5750  L=0.005953  PSNR_f=22.78  PSNR_c=21.67  [pos=7/10, dir=4/4]  (3.8s)\n",
      "Iter  5800  L=0.005648  PSNR_f=23.01  PSNR_c=21.92  [pos=7/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  5800 | fine: L=0.015578, PSNR=18.07\n",
      "Iter  5850  L=0.006234  PSNR_f=22.55  PSNR_c=21.75  [pos=7/10, dir=4/4]  (3.9s)\n",
      "Iter  5900  L=0.005449  PSNR_f=23.14  PSNR_c=22.26  [pos=7/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  5900 | fine: L=0.014534, PSNR=18.38\n",
      "Iter  5950  L=0.005531  PSNR_f=23.13  PSNR_c=21.75  [pos=7/10, dir=4/4]  (3.8s)\n",
      "Iter  6000  L=0.006051  PSNR_f=22.76  PSNR_c=21.22  [pos=7/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  6000 | fine: L=0.013644, PSNR=18.65\n",
      "Iter  6050  L=0.004623  PSNR_f=23.91  PSNR_c=22.54  [pos=7/10, dir=4/4]  (3.8s)\n",
      "Iter  6100  L=0.005089  PSNR_f=23.52  PSNR_c=21.90  [pos=7/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  6100 | fine: L=0.014054, PSNR=18.52\n",
      "Iter  6150  L=0.005235  PSNR_f=23.37  PSNR_c=21.97  [pos=7/10, dir=4/4]  (3.8s)\n",
      "Iter  6200  L=0.004764  PSNR_f=23.76  PSNR_c=22.56  [pos=7/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  6200 | fine: L=0.013899, PSNR=18.57\n",
      "Iter  6250  L=0.005841  PSNR_f=22.92  PSNR_c=21.35  [pos=7/10, dir=4/4]  (3.8s)\n",
      "Iter  6300  L=0.005722  PSNR_f=22.90  PSNR_c=22.30  [pos=7/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  6300 | fine: L=0.013798, PSNR=18.60\n",
      "Iter  6350  L=0.006209  PSNR_f=22.64  PSNR_c=21.14  [pos=7/10, dir=4/4]  (3.8s)\n",
      "Iter  6400  L=0.005582  PSNR_f=23.09  PSNR_c=21.70  [pos=8/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  6400 | fine: L=0.013423, PSNR=18.72\n",
      "Iter  6450  L=0.004941  PSNR_f=23.61  PSNR_c=22.32  [pos=8/10, dir=4/4]  (3.8s)\n",
      "Iter  6500  L=0.005898  PSNR_f=22.84  PSNR_c=21.53  [pos=8/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  6500 | fine: L=0.012709, PSNR=18.96\n",
      "Iter  6550  L=0.005650  PSNR_f=23.04  PSNR_c=21.64  [pos=8/10, dir=4/4]  (3.8s)\n",
      "Iter  6600  L=0.005124  PSNR_f=23.46  PSNR_c=22.10  [pos=8/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  6600 | fine: L=0.012649, PSNR=18.98\n",
      "Iter  6650  L=0.005511  PSNR_f=23.14  PSNR_c=21.81  [pos=8/10, dir=4/4]  (3.8s)\n",
      "Iter  6700  L=0.004363  PSNR_f=24.21  PSNR_c=22.46  [pos=8/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  6700 | fine: L=0.012656, PSNR=18.98\n",
      "Iter  6750  L=0.004659  PSNR_f=23.98  PSNR_c=21.81  [pos=8/10, dir=4/4]  (3.9s)\n",
      "Iter  6800  L=0.005071  PSNR_f=23.51  PSNR_c=22.10  [pos=8/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  6800 | fine: L=0.014142, PSNR=18.49\n",
      "Iter  6850  L=0.005230  PSNR_f=23.40  PSNR_c=21.83  [pos=8/10, dir=4/4]  (3.8s)\n",
      "Iter  6900  L=0.005639  PSNR_f=23.11  PSNR_c=21.21  [pos=8/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  6900 | fine: L=0.012961, PSNR=18.87\n",
      "Iter  6950  L=0.004442  PSNR_f=24.14  PSNR_c=22.32  [pos=8/10, dir=4/4]  (3.9s)\n",
      "Iter  7000  L=0.004719  PSNR_f=23.79  PSNR_c=22.67  [pos=8/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  7000 | fine: L=0.012366, PSNR=19.08\n",
      "Iter  7050  L=0.004243  PSNR_f=24.32  PSNR_c=22.62  [pos=8/10, dir=4/4]  (3.9s)\n",
      "Iter  7100  L=0.005500  PSNR_f=23.17  PSNR_c=21.66  [pos=8/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  7100 | fine: L=0.012170, PSNR=19.15\n",
      "Iter  7150  L=0.006187  PSNR_f=22.70  PSNR_c=20.90  [pos=8/10, dir=4/4]  (3.9s)\n",
      "Iter  7200  L=0.004524  PSNR_f=24.06  PSNR_c=22.21  [pos=9/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  7200 | fine: L=0.013072, PSNR=18.84\n",
      "Iter  7250  L=0.004957  PSNR_f=23.70  PSNR_c=21.58  [pos=9/10, dir=4/4]  (3.8s)\n",
      "Iter  7300  L=0.005366  PSNR_f=23.27  PSNR_c=21.80  [pos=9/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  7300 | fine: L=0.012974, PSNR=18.87\n",
      "Iter  7350  L=0.005361  PSNR_f=23.25  PSNR_c=22.00  [pos=9/10, dir=4/4]  (3.9s)\n",
      "Iter  7400  L=0.004890  PSNR_f=23.70  PSNR_c=22.02  [pos=9/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  7400 | fine: L=0.013415, PSNR=18.72\n",
      "Iter  7450  L=0.004812  PSNR_f=23.81  PSNR_c=21.85  [pos=9/10, dir=4/4]  (4.0s)\n",
      "Iter  7500  L=0.004952  PSNR_f=23.66  PSNR_c=21.89  [pos=9/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  7500 | fine: L=0.011858, PSNR=19.26\n",
      "Iter  7550  L=0.005389  PSNR_f=23.27  PSNR_c=21.69  [pos=9/10, dir=4/4]  (4.0s)\n",
      "Iter  7600  L=0.004346  PSNR_f=24.22  PSNR_c=22.50  [pos=9/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  7600 | fine: L=0.012533, PSNR=19.02\n",
      "Iter  7650  L=0.004653  PSNR_f=23.92  PSNR_c=22.23  [pos=9/10, dir=4/4]  (4.0s)\n",
      "Iter  7700  L=0.004387  PSNR_f=24.15  PSNR_c=22.68  [pos=9/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  7700 | fine: L=0.012845, PSNR=18.91\n",
      "Iter  7750  L=0.004422  PSNR_f=24.17  PSNR_c=22.28  [pos=9/10, dir=4/4]  (3.9s)\n",
      "Iter  7800  L=0.004828  PSNR_f=23.74  PSNR_c=22.18  [pos=9/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  7800 | fine: L=0.012017, PSNR=19.20\n",
      "Iter  7850  L=0.004680  PSNR_f=23.87  PSNR_c=22.37  [pos=9/10, dir=4/4]  (4.0s)\n",
      "Iter  7900  L=0.006382  PSNR_f=22.49  PSNR_c=21.31  [pos=9/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  7900 | fine: L=0.012487, PSNR=19.04\n",
      "Iter  7950  L=0.004107  PSNR_f=24.56  PSNR_c=22.14  [pos=9/10, dir=4/4]  (3.9s)\n",
      "Iter  8000  L=0.005174  PSNR_f=23.45  PSNR_c=21.84  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  8000 | fine: L=0.011978, PSNR=19.22\n",
      "Iter  8050  L=0.005022  PSNR_f=23.57  PSNR_c=22.04  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter  8100  L=0.005139  PSNR_f=23.42  PSNR_c=22.28  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  8100 | fine: L=0.011858, PSNR=19.26\n",
      "Iter  8150  L=0.004685  PSNR_f=23.91  PSNR_c=22.05  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter  8200  L=0.003724  PSNR_f=24.91  PSNR_c=23.08  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  8200 | fine: L=0.012515, PSNR=19.03\n",
      "Iter  8250  L=0.003930  PSNR_f=24.62  PSNR_c=23.21  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter  8300  L=0.005220  PSNR_f=23.47  PSNR_c=21.39  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  8300 | fine: L=0.011170, PSNR=19.52\n",
      "Iter  8350  L=0.004076  PSNR_f=24.55  PSNR_c=22.45  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter  8400  L=0.004971  PSNR_f=23.61  PSNR_c=22.10  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  8400 | fine: L=0.011823, PSNR=19.27\n",
      "Iter  8450  L=0.003664  PSNR_f=24.96  PSNR_c=23.23  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter  8500  L=0.003914  PSNR_f=24.71  PSNR_c=22.72  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  8500 | fine: L=0.011565, PSNR=19.37\n",
      "Iter  8550  L=0.004516  PSNR_f=24.11  PSNR_c=21.99  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter  8600  L=0.004447  PSNR_f=24.17  PSNR_c=22.10  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter  8600 | fine: L=0.011338, PSNR=19.45\n",
      "Iter  8650  L=0.003841  PSNR_f=24.81  PSNR_c=22.70  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter  8700  L=0.004711  PSNR_f=23.81  PSNR_c=22.58  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  8700 | fine: L=0.011318, PSNR=19.46\n",
      "Iter  8750  L=0.004098  PSNR_f=24.43  PSNR_c=23.09  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter  8800  L=0.004784  PSNR_f=23.77  PSNR_c=22.35  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  8800 | fine: L=0.010888, PSNR=19.63\n",
      "Iter  8850  L=0.004041  PSNR_f=24.56  PSNR_c=22.64  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter  8900  L=0.004276  PSNR_f=24.30  PSNR_c=22.52  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  8900 | fine: L=0.011270, PSNR=19.48\n",
      "Iter  8950  L=0.003845  PSNR_f=24.78  PSNR_c=22.84  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter  9000  L=0.004802  PSNR_f=23.75  PSNR_c=22.30  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  9000 | fine: L=0.010367, PSNR=19.84\n",
      "Iter  9050  L=0.004172  PSNR_f=24.36  PSNR_c=22.96  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter  9100  L=0.004003  PSNR_f=24.62  PSNR_c=22.62  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  9100 | fine: L=0.010221, PSNR=19.91\n",
      "Iter  9150  L=0.004549  PSNR_f=23.98  PSNR_c=22.61  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter  9200  L=0.004535  PSNR_f=24.10  PSNR_c=21.90  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  9200 | fine: L=0.010463, PSNR=19.80\n",
      "Iter  9250  L=0.004211  PSNR_f=24.31  PSNR_c=22.97  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter  9300  L=0.004210  PSNR_f=24.34  PSNR_c=22.75  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  9300 | fine: L=0.011190, PSNR=19.51\n",
      "Iter  9350  L=0.004084  PSNR_f=24.54  PSNR_c=22.47  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter  9400  L=0.003821  PSNR_f=24.87  PSNR_c=22.48  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  9400 | fine: L=0.010012, PSNR=19.99\n",
      "Iter  9450  L=0.003515  PSNR_f=25.21  PSNR_c=22.99  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter  9500  L=0.003647  PSNR_f=25.07  PSNR_c=22.71  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  9500 | fine: L=0.010204, PSNR=19.91\n",
      "Iter  9550  L=0.003817  PSNR_f=24.79  PSNR_c=23.02  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter  9600  L=0.003810  PSNR_f=24.86  PSNR_c=22.62  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  9600 | fine: L=0.010351, PSNR=19.85\n",
      "Iter  9650  L=0.005057  PSNR_f=23.49  PSNR_c=22.37  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter  9700  L=0.004435  PSNR_f=24.16  PSNR_c=22.21  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  9700 | fine: L=0.009842, PSNR=20.07\n",
      "Iter  9750  L=0.004876  PSNR_f=23.71  PSNR_c=22.04  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter  9800  L=0.003568  PSNR_f=25.09  PSNR_c=23.30  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  9800 | fine: L=0.010127, PSNR=19.95\n",
      "Iter  9850  L=0.003264  PSNR_f=25.51  PSNR_c=23.46  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter  9900  L=0.004319  PSNR_f=24.30  PSNR_c=22.17  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter  9900 | fine: L=0.010094, PSNR=19.96\n",
      "Iter  9950  L=0.003547  PSNR_f=25.17  PSNR_c=22.96  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 10000  L=0.004303  PSNR_f=24.24  PSNR_c=22.72  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 10000 | fine: L=0.009959, PSNR=20.02\n",
      "Iter 10050  L=0.004161  PSNR_f=24.43  PSNR_c=22.59  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 10100  L=0.003188  PSNR_f=25.58  PSNR_c=23.74  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 10100 | fine: L=0.009568, PSNR=20.19\n",
      "Iter 10150  L=0.004089  PSNR_f=24.45  PSNR_c=23.05  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 10200  L=0.003661  PSNR_f=25.07  PSNR_c=22.60  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 10200 | fine: L=0.009597, PSNR=20.18\n",
      "Iter 10250  L=0.004023  PSNR_f=24.78  PSNR_c=21.59  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 10300  L=0.004553  PSNR_f=24.04  PSNR_c=22.15  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 10300 | fine: L=0.009960, PSNR=20.02\n",
      "Iter 10350  L=0.004562  PSNR_f=24.00  PSNR_c=22.37  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 10400  L=0.003471  PSNR_f=25.30  PSNR_c=22.83  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 10400 | fine: L=0.009189, PSNR=20.37\n",
      "Iter 10450  L=0.003925  PSNR_f=24.61  PSNR_c=23.30  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 10500  L=0.003812  PSNR_f=24.78  PSNR_c=23.15  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 10500 | fine: L=0.009371, PSNR=20.28\n",
      "Iter 10550  L=0.003689  PSNR_f=24.94  PSNR_c=23.13  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 10600  L=0.003986  PSNR_f=24.62  PSNR_c=22.70  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 10600 | fine: L=0.009646, PSNR=20.16\n",
      "Iter 10650  L=0.003525  PSNR_f=25.12  PSNR_c=23.51  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 10700  L=0.004049  PSNR_f=24.59  PSNR_c=22.43  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 10700 | fine: L=0.009488, PSNR=20.23\n",
      "Iter 10750  L=0.003005  PSNR_f=25.96  PSNR_c=23.26  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 10800  L=0.003442  PSNR_f=25.32  PSNR_c=22.99  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 10800 | fine: L=0.009668, PSNR=20.15\n",
      "Iter 10850  L=0.003488  PSNR_f=25.22  PSNR_c=23.19  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 10900  L=0.003953  PSNR_f=24.69  PSNR_c=22.57  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 10900 | fine: L=0.009490, PSNR=20.23\n",
      "Iter 10950  L=0.003078  PSNR_f=25.77  PSNR_c=23.65  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 11000  L=0.003632  PSNR_f=25.00  PSNR_c=23.28  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 11000 | fine: L=0.009511, PSNR=20.22\n",
      "Iter 11050  L=0.003995  PSNR_f=24.68  PSNR_c=22.31  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 11100  L=0.003525  PSNR_f=25.24  PSNR_c=22.76  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 11100 | fine: L=0.008692, PSNR=20.61\n",
      "Iter 11150  L=0.003832  PSNR_f=24.78  PSNR_c=22.98  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 11200  L=0.003664  PSNR_f=25.11  PSNR_c=22.35  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 11200 | fine: L=0.009152, PSNR=20.38\n",
      "Iter 11250  L=0.003797  PSNR_f=24.81  PSNR_c=23.08  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 11300  L=0.003471  PSNR_f=25.22  PSNR_c=23.31  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 11300 | fine: L=0.009498, PSNR=20.22\n",
      "Iter 11350  L=0.004174  PSNR_f=24.49  PSNR_c=22.12  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 11400  L=0.003733  PSNR_f=24.86  PSNR_c=23.28  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 11400 | fine: L=0.008948, PSNR=20.48\n",
      "Iter 11450  L=0.003859  PSNR_f=24.68  PSNR_c=23.45  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 11500  L=0.003581  PSNR_f=25.07  PSNR_c=23.30  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 11500 | fine: L=0.008831, PSNR=20.54\n",
      "Iter 11550  L=0.003748  PSNR_f=24.91  PSNR_c=22.84  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 11600  L=0.003953  PSNR_f=24.67  PSNR_c=22.66  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 11600 | fine: L=0.008774, PSNR=20.57\n",
      "Iter 11650  L=0.003338  PSNR_f=25.43  PSNR_c=23.26  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 11700  L=0.003614  PSNR_f=25.07  PSNR_c=23.00  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 11700 | fine: L=0.009095, PSNR=20.41\n",
      "Iter 11750  L=0.003691  PSNR_f=24.97  PSNR_c=22.98  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 11800  L=0.003356  PSNR_f=25.45  PSNR_c=22.98  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 11800 | fine: L=0.009421, PSNR=20.26\n",
      "Iter 11850  L=0.003171  PSNR_f=25.57  PSNR_c=24.03  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 11900  L=0.003764  PSNR_f=24.90  PSNR_c=22.78  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 11900 | fine: L=0.008402, PSNR=20.76\n",
      "Iter 11950  L=0.003068  PSNR_f=25.83  PSNR_c=23.39  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 12000  L=0.003345  PSNR_f=25.38  PSNR_c=23.47  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 12000 | fine: L=0.009343, PSNR=20.30\n",
      "Iter 12050  L=0.003677  PSNR_f=25.04  PSNR_c=22.63  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 12100  L=0.003769  PSNR_f=25.04  PSNR_c=21.95  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 12100 | fine: L=0.008084, PSNR=20.92\n",
      "Iter 12150  L=0.002957  PSNR_f=25.92  PSNR_c=23.96  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 12200  L=0.004283  PSNR_f=24.23  PSNR_c=22.95  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 12200 | fine: L=0.009245, PSNR=20.34\n",
      "Iter 12250  L=0.003819  PSNR_f=24.85  PSNR_c=22.66  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 12300  L=0.002859  PSNR_f=26.09  PSNR_c=23.98  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 12300 | fine: L=0.009335, PSNR=20.30\n",
      "Iter 12350  L=0.004295  PSNR_f=24.31  PSNR_c=22.32  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 12400  L=0.003363  PSNR_f=25.29  PSNR_c=23.93  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 12400 | fine: L=0.008209, PSNR=20.86\n",
      "Iter 12450  L=0.003460  PSNR_f=25.28  PSNR_c=23.02  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 12500  L=0.003576  PSNR_f=25.05  PSNR_c=23.47  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 12500 | fine: L=0.008789, PSNR=20.56\n",
      "Iter 12550  L=0.003827  PSNR_f=24.89  PSNR_c=22.36  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 12600  L=0.003663  PSNR_f=25.12  PSNR_c=22.32  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 12600 | fine: L=0.009261, PSNR=20.33\n",
      "Iter 12650  L=0.003995  PSNR_f=24.62  PSNR_c=22.65  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 12700  L=0.004253  PSNR_f=24.28  PSNR_c=22.80  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 12700 | fine: L=0.008384, PSNR=20.77\n",
      "Iter 12750  L=0.003044  PSNR_f=25.82  PSNR_c=23.73  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 12800  L=0.003387  PSNR_f=25.41  PSNR_c=22.91  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 12800 | fine: L=0.008911, PSNR=20.50\n",
      "Iter 12850  L=0.003454  PSNR_f=25.29  PSNR_c=23.06  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 12900  L=0.003408  PSNR_f=25.37  PSNR_c=22.98  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 12900 | fine: L=0.008252, PSNR=20.83\n",
      "Iter 12950  L=0.003224  PSNR_f=25.65  PSNR_c=23.02  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 13000  L=0.003466  PSNR_f=25.26  PSNR_c=23.14  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 13000 | fine: L=0.007894, PSNR=21.03\n",
      "Iter 13050  L=0.003807  PSNR_f=24.83  PSNR_c=22.82  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 13100  L=0.003091  PSNR_f=25.76  PSNR_c=23.58  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 13100 | fine: L=0.008751, PSNR=20.58\n",
      "Iter 13150  L=0.004323  PSNR_f=24.27  PSNR_c=22.37  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 13200  L=0.003746  PSNR_f=24.93  PSNR_c=22.76  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 13200 | fine: L=0.008556, PSNR=20.68\n",
      "Iter 13250  L=0.003199  PSNR_f=25.59  PSNR_c=23.56  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 13300  L=0.003442  PSNR_f=25.24  PSNR_c=23.44  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 13300 | fine: L=0.008286, PSNR=20.82\n",
      "Iter 13350  L=0.003589  PSNR_f=25.11  PSNR_c=22.98  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 13400  L=0.003302  PSNR_f=25.51  PSNR_c=23.09  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 13400 | fine: L=0.008598, PSNR=20.66\n",
      "Iter 13450  L=0.003219  PSNR_f=25.59  PSNR_c=23.38  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 13500  L=0.003625  PSNR_f=25.17  PSNR_c=22.35  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 13500 | fine: L=0.008573, PSNR=20.67\n",
      "Iter 13550  L=0.003007  PSNR_f=25.86  PSNR_c=23.85  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 13600  L=0.003207  PSNR_f=25.64  PSNR_c=23.22  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 13600 | fine: L=0.008698, PSNR=20.61\n",
      "Iter 13650  L=0.003440  PSNR_f=25.32  PSNR_c=22.99  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 13700  L=0.003574  PSNR_f=25.15  PSNR_c=22.87  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 13700 | fine: L=0.008360, PSNR=20.78\n",
      "Iter 13750  L=0.003805  PSNR_f=24.80  PSNR_c=23.07  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 13800  L=0.003221  PSNR_f=25.56  PSNR_c=23.58  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 13800 | fine: L=0.008754, PSNR=20.58\n",
      "Iter 13850  L=0.002993  PSNR_f=25.84  PSNR_c=24.13  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 13900  L=0.003520  PSNR_f=25.18  PSNR_c=23.13  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 13900 | fine: L=0.008108, PSNR=20.91\n",
      "Iter 13950  L=0.003301  PSNR_f=25.44  PSNR_c=23.50  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 14000  L=0.003776  PSNR_f=24.88  PSNR_c=22.78  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 14000 | fine: L=0.008378, PSNR=20.77\n",
      "Iter 14050  L=0.003724  PSNR_f=25.00  PSNR_c=22.53  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 14100  L=0.003630  PSNR_f=25.05  PSNR_c=23.00  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 14100 | fine: L=0.008418, PSNR=20.75\n",
      "Iter 14150  L=0.002805  PSNR_f=26.37  PSNR_c=23.03  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 14200  L=0.003238  PSNR_f=25.62  PSNR_c=23.05  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 14200 | fine: L=0.008647, PSNR=20.63\n",
      "Iter 14250  L=0.003153  PSNR_f=25.83  PSNR_c=22.69  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 14300  L=0.002885  PSNR_f=26.03  PSNR_c=24.11  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 14300 | fine: L=0.008950, PSNR=20.48\n",
      "Iter 14350  L=0.003225  PSNR_f=25.63  PSNR_c=23.12  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 14400  L=0.003717  PSNR_f=24.95  PSNR_c=22.88  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 14400 | fine: L=0.009161, PSNR=20.38\n",
      "Iter 14450  L=0.003529  PSNR_f=25.29  PSNR_c=22.46  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 14500  L=0.002970  PSNR_f=25.98  PSNR_c=23.52  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 14500 | fine: L=0.008539, PSNR=20.69\n",
      "Iter 14550  L=0.002632  PSNR_f=26.50  PSNR_c=24.04  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 14600  L=0.003640  PSNR_f=24.95  PSNR_c=23.59  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 14600 | fine: L=0.008788, PSNR=20.56\n",
      "Iter 14650  L=0.003780  PSNR_f=24.89  PSNR_c=22.69  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 14700  L=0.003549  PSNR_f=25.10  PSNR_c=23.41  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 14700 | fine: L=0.008553, PSNR=20.68\n",
      "Iter 14750  L=0.003047  PSNR_f=25.83  PSNR_c=23.62  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 14800  L=0.003545  PSNR_f=25.11  PSNR_c=23.36  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 14800 | fine: L=0.008481, PSNR=20.72\n",
      "Iter 14850  L=0.003088  PSNR_f=25.82  PSNR_c=23.29  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 14900  L=0.002846  PSNR_f=26.11  PSNR_c=24.04  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 14900 | fine: L=0.008668, PSNR=20.62\n",
      "Iter 14950  L=0.003375  PSNR_f=25.34  PSNR_c=23.49  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 15000  L=0.003136  PSNR_f=25.61  PSNR_c=24.12  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 15000 | fine: L=0.008594, PSNR=20.66\n",
      "Iter 15050  L=0.003093  PSNR_f=25.74  PSNR_c=23.67  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 15100  L=0.003268  PSNR_f=25.53  PSNR_c=23.28  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 15100 | fine: L=0.008823, PSNR=20.54\n",
      "Iter 15150  L=0.003501  PSNR_f=25.13  PSNR_c=23.61  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 15200  L=0.003081  PSNR_f=25.94  PSNR_c=22.73  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 15200 | fine: L=0.008781, PSNR=20.56\n",
      "Iter 15250  L=0.003293  PSNR_f=25.43  PSNR_c=23.67  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 15300  L=0.003226  PSNR_f=25.66  PSNR_c=22.92  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 15300 | fine: L=0.008430, PSNR=20.74\n",
      "Iter 15350  L=0.003072  PSNR_f=25.84  PSNR_c=23.30  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 15400  L=0.003357  PSNR_f=25.36  PSNR_c=23.53  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 15400 | fine: L=0.008438, PSNR=20.74\n",
      "Iter 15450  L=0.003189  PSNR_f=25.71  PSNR_c=22.98  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 15500  L=0.002916  PSNR_f=26.03  PSNR_c=23.74  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 15500 | fine: L=0.008842, PSNR=20.53\n",
      "Iter 15550  L=0.004085  PSNR_f=24.58  PSNR_c=22.20  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 15600  L=0.002913  PSNR_f=26.16  PSNR_c=23.09  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 15600 | fine: L=0.007921, PSNR=21.01\n",
      "Iter 15650  L=0.002984  PSNR_f=25.99  PSNR_c=23.29  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 15700  L=0.003429  PSNR_f=25.28  PSNR_c=23.35  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 15700 | fine: L=0.008256, PSNR=20.83\n",
      "Iter 15750  L=0.003159  PSNR_f=25.75  PSNR_c=23.02  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 15800  L=0.002443  PSNR_f=26.84  PSNR_c=24.30  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 15800 | fine: L=0.008127, PSNR=20.90\n",
      "Iter 15850  L=0.003072  PSNR_f=25.90  PSNR_c=22.97  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 15900  L=0.003407  PSNR_f=25.33  PSNR_c=23.22  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 15900 | fine: L=0.008403, PSNR=20.76\n",
      "Iter 15950  L=0.003440  PSNR_f=25.30  PSNR_c=23.09  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 16000  L=0.003303  PSNR_f=25.59  PSNR_c=22.67  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 16000 | fine: L=0.007889, PSNR=21.03\n",
      "Iter 16050  L=0.003282  PSNR_f=25.59  PSNR_c=22.84  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 16100  L=0.003345  PSNR_f=25.48  PSNR_c=22.88  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 16100 | fine: L=0.007534, PSNR=21.23\n",
      "Iter 16150  L=0.002989  PSNR_f=26.02  PSNR_c=23.13  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 16200  L=0.003271  PSNR_f=25.64  PSNR_c=22.65  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 16200 | fine: L=0.007387, PSNR=21.32\n",
      "Iter 16250  L=0.003030  PSNR_f=25.77  PSNR_c=24.17  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 16300  L=0.002855  PSNR_f=26.16  PSNR_c=23.61  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 16300 | fine: L=0.007392, PSNR=21.31\n",
      "Iter 16350  L=0.003712  PSNR_f=25.01  PSNR_c=22.56  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 16400  L=0.003387  PSNR_f=25.30  PSNR_c=23.58  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 16400 | fine: L=0.007513, PSNR=21.24\n",
      "Iter 16450  L=0.003187  PSNR_f=25.68  PSNR_c=23.14  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 16500  L=0.003628  PSNR_f=25.11  PSNR_c=22.66  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 16500 | fine: L=0.008466, PSNR=20.72\n",
      "Iter 16550  L=0.002767  PSNR_f=26.25  PSNR_c=24.02  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 16600  L=0.002885  PSNR_f=26.24  PSNR_c=22.94  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 16600 | fine: L=0.008117, PSNR=20.91\n",
      "Iter 16650  L=0.003206  PSNR_f=25.76  PSNR_c=22.60  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 16700  L=0.003472  PSNR_f=25.29  PSNR_c=22.91  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 16700 | fine: L=0.008462, PSNR=20.73\n",
      "Iter 16750  L=0.003333  PSNR_f=25.39  PSNR_c=23.52  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 16800  L=0.003234  PSNR_f=25.64  PSNR_c=22.97  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 16800 | fine: L=0.007602, PSNR=21.19\n",
      "Iter 16850  L=0.002753  PSNR_f=26.39  PSNR_c=23.41  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 16900  L=0.003013  PSNR_f=25.86  PSNR_c=23.81  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 16900 | fine: L=0.007979, PSNR=20.98\n",
      "Iter 16950  L=0.002923  PSNR_f=25.99  PSNR_c=23.89  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 17000  L=0.002536  PSNR_f=26.71  PSNR_c=23.95  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 17000 | fine: L=0.008565, PSNR=20.67\n",
      "Iter 17050  L=0.003397  PSNR_f=25.34  PSNR_c=23.24  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 17100  L=0.003013  PSNR_f=25.87  PSNR_c=23.72  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 17100 | fine: L=0.008229, PSNR=20.85\n",
      "Iter 17150  L=0.003348  PSNR_f=25.37  PSNR_c=23.51  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 17200  L=0.003177  PSNR_f=25.71  PSNR_c=23.08  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 17200 | fine: L=0.008058, PSNR=20.94\n",
      "Iter 17250  L=0.003737  PSNR_f=24.97  PSNR_c=22.55  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 17300  L=0.002622  PSNR_f=26.49  PSNR_c=24.20  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 17300 | fine: L=0.007611, PSNR=21.19\n",
      "Iter 17350  L=0.003203  PSNR_f=25.71  PSNR_c=22.87  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 17400  L=0.002898  PSNR_f=26.11  PSNR_c=23.46  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 17400 | fine: L=0.008240, PSNR=20.84\n",
      "Iter 17450  L=0.003597  PSNR_f=25.10  PSNR_c=22.98  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 17500  L=0.003358  PSNR_f=25.48  PSNR_c=22.78  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 17500 | fine: L=0.007654, PSNR=21.16\n",
      "Iter 17550  L=0.002884  PSNR_f=26.15  PSNR_c=23.42  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 17600  L=0.002873  PSNR_f=26.11  PSNR_c=23.73  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 17600 | fine: L=0.007608, PSNR=21.19\n",
      "Iter 17650  L=0.003762  PSNR_f=24.96  PSNR_c=22.43  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 17700  L=0.003104  PSNR_f=25.74  PSNR_c=23.62  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 17700 | fine: L=0.008376, PSNR=20.77\n",
      "Iter 17750  L=0.003432  PSNR_f=25.28  PSNR_c=23.30  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 17800  L=0.002903  PSNR_f=26.10  PSNR_c=23.48  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 17800 | fine: L=0.007744, PSNR=21.11\n",
      "Iter 17850  L=0.002898  PSNR_f=26.05  PSNR_c=23.85  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 17900  L=0.002811  PSNR_f=26.20  PSNR_c=23.86  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 17900 | fine: L=0.007887, PSNR=21.03\n",
      "Iter 17950  L=0.003409  PSNR_f=25.39  PSNR_c=22.86  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 18000  L=0.002434  PSNR_f=26.93  PSNR_c=23.90  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 18000 | fine: L=0.008326, PSNR=20.80\n",
      "Iter 18050  L=0.003157  PSNR_f=25.64  PSNR_c=23.66  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 18100  L=0.002148  PSNR_f=27.55  PSNR_c=24.10  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 18100 | fine: L=0.008184, PSNR=20.87\n",
      "Iter 18150  L=0.003264  PSNR_f=25.52  PSNR_c=23.40  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 18200  L=0.002822  PSNR_f=26.12  PSNR_c=24.23  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 18200 | fine: L=0.007671, PSNR=21.15\n",
      "Iter 18250  L=0.002933  PSNR_f=26.08  PSNR_c=23.28  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 18300  L=0.003412  PSNR_f=25.31  PSNR_c=23.32  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 18300 | fine: L=0.007991, PSNR=20.97\n",
      "Iter 18350  L=0.002664  PSNR_f=26.46  PSNR_c=23.92  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 18400  L=0.002951  PSNR_f=26.09  PSNR_c=23.09  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 18400 | fine: L=0.008110, PSNR=20.91\n",
      "Iter 18450  L=0.003749  PSNR_f=24.93  PSNR_c=22.72  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 18500  L=0.002393  PSNR_f=27.02  PSNR_c=23.93  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 18500 | fine: L=0.007864, PSNR=21.04\n",
      "Iter 18550  L=0.003360  PSNR_f=25.42  PSNR_c=23.10  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 18600  L=0.003156  PSNR_f=25.59  PSNR_c=24.02  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 18600 | fine: L=0.007805, PSNR=21.08\n",
      "Iter 18650  L=0.002780  PSNR_f=26.36  PSNR_c=23.32  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 18700  L=0.003633  PSNR_f=25.09  PSNR_c=22.71  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 18700 | fine: L=0.008407, PSNR=20.75\n",
      "Iter 18750  L=0.002568  PSNR_f=26.64  PSNR_c=23.96  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 18800  L=0.003085  PSNR_f=25.86  PSNR_c=23.11  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 18800 | fine: L=0.007815, PSNR=21.07\n",
      "Iter 18850  L=0.003827  PSNR_f=24.83  PSNR_c=22.70  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 18900  L=0.003482  PSNR_f=25.27  PSNR_c=22.91  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 18900 | fine: L=0.007488, PSNR=21.26\n",
      "Iter 18950  L=0.002555  PSNR_f=26.57  PSNR_c=24.51  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 19000  L=0.003013  PSNR_f=25.90  PSNR_c=23.55  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 19000 | fine: L=0.007616, PSNR=21.18\n",
      "Iter 19050  L=0.004067  PSNR_f=24.56  PSNR_c=22.48  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 19100  L=0.002771  PSNR_f=26.29  PSNR_c=23.78  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 19100 | fine: L=0.007600, PSNR=21.19\n",
      "Iter 19150  L=0.002901  PSNR_f=26.09  PSNR_c=23.55  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 19200  L=0.003385  PSNR_f=25.34  PSNR_c=23.34  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 19200 | fine: L=0.007563, PSNR=21.21\n",
      "Iter 19250  L=0.002479  PSNR_f=26.80  PSNR_c=24.12  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 19300  L=0.003059  PSNR_f=25.86  PSNR_c=23.35  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 19300 | fine: L=0.007905, PSNR=21.02\n",
      "Iter 19350  L=0.002533  PSNR_f=26.79  PSNR_c=23.59  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 19400  L=0.003469  PSNR_f=25.44  PSNR_c=22.11  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 19400 | fine: L=0.007654, PSNR=21.16\n",
      "Iter 19450  L=0.002922  PSNR_f=25.98  PSNR_c=24.02  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 19500  L=0.002666  PSNR_f=26.48  PSNR_c=23.81  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 19500 | fine: L=0.007583, PSNR=21.20\n",
      "Iter 19550  L=0.003515  PSNR_f=25.18  PSNR_c=23.15  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 19600  L=0.003303  PSNR_f=25.37  PSNR_c=23.99  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 19600 | fine: L=0.008051, PSNR=20.94\n",
      "Iter 19650  L=0.002397  PSNR_f=26.91  PSNR_c=24.44  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 19700  L=0.002322  PSNR_f=27.05  PSNR_c=24.57  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 19700 | fine: L=0.007563, PSNR=21.21\n",
      "Iter 19750  L=0.002303  PSNR_f=27.03  PSNR_c=24.91  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 19800  L=0.004213  PSNR_f=24.36  PSNR_c=22.62  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 19800 | fine: L=0.007576, PSNR=21.21\n",
      "Iter 19850  L=0.003112  PSNR_f=25.83  PSNR_c=23.03  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 19900  L=0.003013  PSNR_f=25.89  PSNR_c=23.60  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 19900 | fine: L=0.007109, PSNR=21.48\n",
      "Iter 19950  L=0.002823  PSNR_f=26.25  PSNR_c=23.44  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 20000  L=0.002993  PSNR_f=25.98  PSNR_c=23.31  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 20000 | fine: L=0.007432, PSNR=21.29\n",
      "Iter 20050  L=0.002722  PSNR_f=26.35  PSNR_c=23.92  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 20100  L=0.002741  PSNR_f=26.33  PSNR_c=23.82  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 20100 | fine: L=0.007598, PSNR=21.19\n",
      "Iter 20150  L=0.002971  PSNR_f=25.96  PSNR_c=23.59  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 20200  L=0.002574  PSNR_f=26.59  PSNR_c=24.18  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 20200 | fine: L=0.007876, PSNR=21.04\n",
      "Iter 20250  L=0.002647  PSNR_f=26.51  PSNR_c=23.84  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 20300  L=0.002953  PSNR_f=25.94  PSNR_c=23.94  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 20300 | fine: L=0.008215, PSNR=20.85\n",
      "Iter 20350  L=0.002683  PSNR_f=26.33  PSNR_c=24.48  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 20400  L=0.003024  PSNR_f=26.08  PSNR_c=22.55  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 20400 | fine: L=0.007383, PSNR=21.32\n",
      "Iter 20450  L=0.002566  PSNR_f=26.63  PSNR_c=24.03  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 20500  L=0.002531  PSNR_f=26.80  PSNR_c=23.56  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 20500 | fine: L=0.007651, PSNR=21.16\n",
      "Iter 20550  L=0.002985  PSNR_f=25.98  PSNR_c=23.39  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 20600  L=0.002966  PSNR_f=25.97  PSNR_c=23.61  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 20600 | fine: L=0.007511, PSNR=21.24\n",
      "Iter 20650  L=0.003205  PSNR_f=25.66  PSNR_c=23.10  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 20700  L=0.002810  PSNR_f=26.26  PSNR_c=23.54  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 20700 | fine: L=0.007493, PSNR=21.25\n",
      "Iter 20750  L=0.002639  PSNR_f=26.59  PSNR_c=23.50  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 20800  L=0.003205  PSNR_f=25.55  PSNR_c=23.78  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 20800 | fine: L=0.007235, PSNR=21.41\n",
      "Iter 20850  L=0.002835  PSNR_f=26.35  PSNR_c=22.85  [pos=10/10, dir=4/4]  (3.8s)\n",
      "Iter 20900  L=0.002921  PSNR_f=26.10  PSNR_c=23.29  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 20900 | fine: L=0.007994, PSNR=20.97\n",
      "Iter 20950  L=0.002457  PSNR_f=26.82  PSNR_c=24.26  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 21000  L=0.003147  PSNR_f=25.76  PSNR_c=23.09  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 21000 | fine: L=0.008253, PSNR=20.83\n",
      "Iter 21050  L=0.002845  PSNR_f=26.17  PSNR_c=23.65  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 21100  L=0.003144  PSNR_f=25.64  PSNR_c=23.80  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 21100 | fine: L=0.007237, PSNR=21.40\n",
      "Iter 21150  L=0.002435  PSNR_f=26.85  PSNR_c=24.34  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 21200  L=0.002730  PSNR_f=26.36  PSNR_c=23.76  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 21200 | fine: L=0.007387, PSNR=21.32\n",
      "Iter 21250  L=0.002727  PSNR_f=26.28  PSNR_c=24.30  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 21300  L=0.002435  PSNR_f=26.87  PSNR_c=24.23  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 21300 | fine: L=0.007703, PSNR=21.13\n",
      "Iter 21350  L=0.002459  PSNR_f=26.79  PSNR_c=24.37  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 21400  L=0.002703  PSNR_f=26.33  PSNR_c=24.23  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 21400 | fine: L=0.007556, PSNR=21.22\n",
      "Iter 21450  L=0.002541  PSNR_f=26.75  PSNR_c=23.70  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 21500  L=0.003197  PSNR_f=25.60  PSNR_c=23.55  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 21500 | fine: L=0.008354, PSNR=20.78\n",
      "Iter 21550  L=0.002696  PSNR_f=26.35  PSNR_c=24.25  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 21600  L=0.003300  PSNR_f=25.46  PSNR_c=23.39  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 21600 | fine: L=0.007612, PSNR=21.18\n",
      "Iter 21650  L=0.002941  PSNR_f=26.07  PSNR_c=23.29  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 21700  L=0.002831  PSNR_f=26.16  PSNR_c=23.88  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 21700 | fine: L=0.007429, PSNR=21.29\n",
      "Iter 21750  L=0.003008  PSNR_f=25.90  PSNR_c=23.58  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 21800  L=0.002745  PSNR_f=26.39  PSNR_c=23.49  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 21800 | fine: L=0.007542, PSNR=21.22\n",
      "Iter 21850  L=0.002445  PSNR_f=26.77  PSNR_c=24.70  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 21900  L=0.003027  PSNR_f=25.91  PSNR_c=23.34  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 21900 | fine: L=0.008578, PSNR=20.67\n",
      "Iter 21950  L=0.002705  PSNR_f=26.37  PSNR_c=23.99  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 22000  L=0.003123  PSNR_f=25.85  PSNR_c=22.81  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 22000 | fine: L=0.007495, PSNR=21.25\n",
      "Iter 22050  L=0.003078  PSNR_f=25.85  PSNR_c=23.23  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 22100  L=0.002743  PSNR_f=26.45  PSNR_c=23.20  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 22100 | fine: L=0.007592, PSNR=21.20\n",
      "Iter 22150  L=0.002171  PSNR_f=27.46  PSNR_c=24.23  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 22200  L=0.002841  PSNR_f=26.20  PSNR_c=23.54  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 22200 | fine: L=0.006853, PSNR=21.64\n",
      "Iter 22250  L=0.003030  PSNR_f=25.85  PSNR_c=23.64  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 22300  L=0.003618  PSNR_f=25.08  PSNR_c=22.90  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 22300 | fine: L=0.007749, PSNR=21.11\n",
      "Iter 22350  L=0.002912  PSNR_f=26.21  PSNR_c=22.84  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 22400  L=0.002496  PSNR_f=26.75  PSNR_c=24.17  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 22400 | fine: L=0.007727, PSNR=21.12\n",
      "Iter 22450  L=0.002566  PSNR_f=26.61  PSNR_c=24.14  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 22500  L=0.003148  PSNR_f=25.71  PSNR_c=23.34  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 22500 | fine: L=0.007440, PSNR=21.28\n",
      "Iter 22550  L=0.002433  PSNR_f=26.79  PSNR_c=24.70  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 22600  L=0.002898  PSNR_f=26.02  PSNR_c=23.98  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 22600 | fine: L=0.007450, PSNR=21.28\n",
      "Iter 22650  L=0.003135  PSNR_f=25.62  PSNR_c=24.02  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 22700  L=0.003483  PSNR_f=25.17  PSNR_c=23.54  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 22700 | fine: L=0.007639, PSNR=21.17\n",
      "Iter 22750  L=0.002909  PSNR_f=26.08  PSNR_c=23.52  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 22800  L=0.002851  PSNR_f=26.20  PSNR_c=23.43  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 22800 | fine: L=0.007553, PSNR=21.22\n",
      "Iter 22850  L=0.003428  PSNR_f=25.26  PSNR_c=23.51  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 22900  L=0.002612  PSNR_f=26.58  PSNR_c=23.81  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 22900 | fine: L=0.007355, PSNR=21.33\n",
      "Iter 22950  L=0.002872  PSNR_f=26.16  PSNR_c=23.44  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 23000  L=0.002583  PSNR_f=26.71  PSNR_c=23.46  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 23000 | fine: L=0.007538, PSNR=21.23\n",
      "Iter 23050  L=0.002131  PSNR_f=27.45  PSNR_c=24.79  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 23100  L=0.003024  PSNR_f=25.94  PSNR_c=23.23  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 23100 | fine: L=0.007654, PSNR=21.16\n",
      "Iter 23150  L=0.002025  PSNR_f=27.66  PSNR_c=25.04  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 23200  L=0.002872  PSNR_f=26.12  PSNR_c=23.66  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 23200 | fine: L=0.007647, PSNR=21.16\n",
      "Iter 23250  L=0.003114  PSNR_f=25.75  PSNR_c=23.47  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 23300  L=0.002854  PSNR_f=26.16  PSNR_c=23.64  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 23300 | fine: L=0.007589, PSNR=21.20\n",
      "Iter 23350  L=0.002840  PSNR_f=26.14  PSNR_c=23.92  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 23400  L=0.003411  PSNR_f=25.33  PSNR_c=23.18  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 23400 | fine: L=0.008007, PSNR=20.97\n",
      "Iter 23450  L=0.002734  PSNR_f=26.44  PSNR_c=23.35  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 23500  L=0.003165  PSNR_f=25.59  PSNR_c=23.93  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 23500 | fine: L=0.007095, PSNR=21.49\n",
      "Iter 23550  L=0.002521  PSNR_f=26.72  PSNR_c=24.05  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 23600  L=0.002894  PSNR_f=26.06  PSNR_c=23.80  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 23600 | fine: L=0.007386, PSNR=21.32\n",
      "Iter 23650  L=0.002711  PSNR_f=26.42  PSNR_c=23.64  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 23700  L=0.002500  PSNR_f=26.75  PSNR_c=24.14  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 23700 | fine: L=0.007481, PSNR=21.26\n",
      "Iter 23750  L=0.002753  PSNR_f=26.27  PSNR_c=24.05  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 23800  L=0.002161  PSNR_f=27.40  PSNR_c=24.66  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 23800 | fine: L=0.007498, PSNR=21.25\n",
      "Iter 23850  L=0.002641  PSNR_f=26.58  PSNR_c=23.54  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 23900  L=0.003208  PSNR_f=25.63  PSNR_c=23.27  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 23900 | fine: L=0.007367, PSNR=21.33\n",
      "Iter 23950  L=0.002567  PSNR_f=26.71  PSNR_c=23.65  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 24000  L=0.003181  PSNR_f=25.59  PSNR_c=23.74  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 24000 | fine: L=0.007460, PSNR=21.27\n",
      "Iter 24050  L=0.002832  PSNR_f=26.20  PSNR_c=23.63  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 24100  L=0.002793  PSNR_f=26.31  PSNR_c=23.45  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 24100 | fine: L=0.007451, PSNR=21.28\n",
      "Iter 24150  L=0.002737  PSNR_f=26.39  PSNR_c=23.57  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 24200  L=0.002263  PSNR_f=27.13  PSNR_c=24.84  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 24200 | fine: L=0.007540, PSNR=21.23\n",
      "Iter 24250  L=0.002791  PSNR_f=26.34  PSNR_c=23.32  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 24300  L=0.003137  PSNR_f=25.77  PSNR_c=23.14  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 24300 | fine: L=0.007784, PSNR=21.09\n",
      "Iter 24350  L=0.002882  PSNR_f=26.20  PSNR_c=23.14  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 24400  L=0.003389  PSNR_f=25.33  PSNR_c=23.38  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 24400 | fine: L=0.007089, PSNR=21.49\n",
      "Iter 24450  L=0.002375  PSNR_f=26.96  PSNR_c=24.44  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 24500  L=0.002813  PSNR_f=26.25  PSNR_c=23.54  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 24500 | fine: L=0.007233, PSNR=21.41\n",
      "Iter 24550  L=0.003576  PSNR_f=25.12  PSNR_c=23.01  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 24600  L=0.002587  PSNR_f=26.62  PSNR_c=23.90  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 24600 | fine: L=0.007501, PSNR=21.25\n",
      "Iter 24650  L=0.003007  PSNR_f=25.99  PSNR_c=23.11  [pos=10/10, dir=4/4]  (4.0s)\n",
      "Iter 24700  L=0.002329  PSNR_f=27.01  PSNR_c=24.71  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 24700 | fine: L=0.007061, PSNR=21.51\n",
      "Iter 24750  L=0.002710  PSNR_f=26.45  PSNR_c=23.49  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 24800  L=0.002689  PSNR_f=26.42  PSNR_c=23.91  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 24800 | fine: L=0.007283, PSNR=21.38\n",
      "Iter 24850  L=0.002471  PSNR_f=26.92  PSNR_c=23.58  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 24900  L=0.003488  PSNR_f=25.23  PSNR_c=23.11  [pos=10/10, dir=4/4]  (3.8s)\n",
      "[TEST] iter 24900 | fine: L=0.007888, PSNR=21.03\n",
      "Iter 24950  L=0.002619  PSNR_f=26.58  PSNR_c=23.78  [pos=10/10, dir=4/4]  (3.9s)\n",
      "Iter 25000  L=0.002498  PSNR_f=26.64  PSNR_c=24.80  [pos=10/10, dir=4/4]  (3.9s)\n",
      "[TEST] iter 25000 | fine: L=0.007281, PSNR=21.38\n",
      "Finished training.\n",
      "Peak GPU memory: 11.47 GB\n",
      "Saved:\n",
      "  training_metrics.csv, training_metrics_eval.csv\n",
      "  train_vs_test_loss_f.png, train_vs_test_psnr_f.png\n",
      "  train_loss.png, train_psnr.png, pe_active_bands.png\n",
      "  nerf_tiny_pe.pt\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision(\"high\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "basedir = \"../data/nerf_synthetic/lego\"\n",
    "\n",
    "# Load dataset\n",
    "imgs_np, poses_np, hwf, i_split = load_blender_data_raw(basedir)\n",
    "H, W, focal = hwf\n",
    "\n",
    "imgs_torch  = torch.from_numpy(imgs_np).float().to(device)\n",
    "poses_torch = torch.from_numpy(poses_np).float().to(device)\n",
    "\n",
    "# Handle alpha channel (RGBA  RGB on white)\n",
    "if imgs_torch.shape[-1] == 4:\n",
    "    rgb, a = imgs_torch[..., :3], imgs_torch[..., 3:4]\n",
    "    imgs_torch = rgb * a + (1.0 - a)\n",
    "\n",
    "# Downsample\n",
    "down = 2\n",
    "if down > 1:\n",
    "    imgs_chw = imgs_torch.permute(0, 3, 1, 2)\n",
    "    imgs_chw = F.interpolate(imgs_chw, size=(H // down, W // down), mode=\"area\")\n",
    "    imgs_torch = imgs_chw.permute(0, 2, 3, 1).contiguous()\n",
    "    H //= down; W //= down; focal /= down\n",
    "\n",
    "# Split train/test\n",
    "i_train = i_split[0]\n",
    "i_test  = i_split[2]\n",
    "\n",
    "imgs_train, poses_train = imgs_torch[i_train], poses_torch[i_train]\n",
    "imgs_test,  poses_test  = imgs_torch[i_test],  poses_torch[i_test]\n",
    "\n",
    "# Ray banks\n",
    "with torch.no_grad():\n",
    "    rays_o_all, rays_d_all, rgb_all = build_ray_bank(imgs_train, poses_train, H, W, focal)\n",
    "    rays_o_all = rays_o_all.to(device).contiguous()\n",
    "    rays_d_all = rays_d_all.to(device).contiguous()\n",
    "    rgb_all    = rgb_all.to(device).contiguous()\n",
    "    rays_d_all_unit = F.normalize(rays_d_all, dim=-1)\n",
    "\n",
    "    rays_o_test, rays_d_test, rgb_test = build_ray_bank(imgs_test, poses_test, H, W, focal)\n",
    "    rays_o_test = rays_o_test.to(device).contiguous()\n",
    "    rays_d_test = rays_d_test.to(device).contiguous()\n",
    "    rgb_test    = rgb_test.to(device).contiguous()\n",
    "    rays_d_test_unit = F.normalize(rays_d_test, dim=-1)\n",
    "\n",
    "# Fixed evaluation subset\n",
    "torch.manual_seed(0)\n",
    "E = min(8192, rays_o_test.shape[0])\n",
    "perm = torch.randperm(rays_o_test.shape[0], device=device)\n",
    "eval_idx = perm[:E]\n",
    "rays_o_eval     = rays_o_test[eval_idx].contiguous()\n",
    "rays_d_eval     = rays_d_test[eval_idx].contiguous()\n",
    "rays_d_eval_unit= rays_d_test_unit[eval_idx].contiguous()\n",
    "rgb_eval        = rgb_test[eval_idx].contiguous()\n",
    "\n",
    "# Model\n",
    "model = TinyNeRF_PE(Lx=10, Ld=4, hidden=256).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "pe_pos_end = 8000\n",
    "pe_dir_end = 4000\n",
    "near, far = 2.0, 6.0\n",
    "S_coarse, S_fine = 64, 128\n",
    "B = 2048\n",
    "iters = 25000\n",
    "\n",
    "# Logging\n",
    "hist_iter, hist_loss_f, hist_loss_c = [], [], []\n",
    "hist_psnr_f, hist_psnr_c = [], []\n",
    "hist_pos_on, hist_dir_on = [], []\n",
    "hist_iter_eval, hist_test_loss_f, hist_test_psnr_f = [], [], []\n",
    "\n",
    "def _log(it, loss_main, loss_aux, psnr_f, psnr_c, npos, ndir):\n",
    "    hist_iter.append(it)\n",
    "    hist_loss_f.append(float(loss_main.detach().cpu()))\n",
    "    hist_loss_c.append(float(loss_aux.detach().cpu()))\n",
    "    hist_psnr_f.append(float(psnr_f))\n",
    "    hist_psnr_c.append(float(psnr_c))\n",
    "    hist_pos_on.append(int(npos))\n",
    "    hist_dir_on.append(int(ndir))\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_fine(model, rays_o, rays_d, rays_d_unit, target,\n",
    "              near, far, S_coarse=32, S_fine=64, chunk=1024):\n",
    "\n",
    "    model.eval()\n",
    "    N = rays_o.shape[0]\n",
    "    err_sum = 0.0\n",
    "\n",
    "    for s in range(0, N, chunk):\n",
    "        e = min(N, s + chunk)\n",
    "        ro, rd = rays_o[s:e], rays_d[s:e]\n",
    "        rdu, tgt = rays_d_unit[s:e], target[s:e]\n",
    "\n",
    "        z_c, pts_c = sample_along_rays(ro, rd, near, far, S=S_coarse, stratified=False)\n",
    "        dirs_c = rdu[:, None, :].expand(-1, S_coarse, -1)\n",
    "        rgb_c, sigma_c = model(pts_c, dirs_c)\n",
    "        _, _, w_c = volume_render(rgb_c, sigma_c, z_c, rd, white_bkgd=True)\n",
    "\n",
    "        bins  = 0.5 * (z_c[:, 1:] + z_c[:, :-1])\n",
    "        w_mid = w_c[:, 1:-1, 0]\n",
    "        L = min(bins.shape[-1], w_mid.shape[-1])\n",
    "\n",
    "        z_f = sample_pdf(bins[:, :L].contiguous(),\n",
    "                         w_mid[:, :L].contiguous(),\n",
    "                         N_importance=S_fine,\n",
    "                         deterministic=True)\n",
    "\n",
    "        z_all, _ = torch.sort(torch.cat([z_c, z_f], dim=-1), dim=-1)\n",
    "        pts_all  = ro[:, None, :] + rd[:, None, :] * z_all[..., None]\n",
    "        dirs_all = rdu[:, None, :].expand(-1, z_all.shape[1], -1)\n",
    "\n",
    "        rgb_f, sigma_f = model(pts_all, dirs_all)\n",
    "        rgb_map_f, _, _ = volume_render(rgb_f, sigma_f, z_all, rd, white_bkgd=True)\n",
    "\n",
    "        err_sum += F.mse_loss(rgb_map_f, tgt, reduction='sum').item()\n",
    "\n",
    "    model.train()\n",
    "    mse = err_sum / N\n",
    "    psnr = 10.0 * math.log10(1.0 / max(mse, 1e-12))\n",
    "    return mse, psnr\n",
    "\n",
    "# Training\n",
    "model.train()\n",
    "t0 = time.time()\n",
    "total_rays = rays_o_all.shape[0]\n",
    "test_every = 100\n",
    "\n",
    "for it in range(1, iters + 1):\n",
    "\n",
    "    model.pe_xyz.set_window_by_iter(it, pe_pos_end)\n",
    "    model.pe_dir.set_window_by_iter(it, pe_dir_end)\n",
    "\n",
    "    idx = torch.randint(0, total_rays, (B,), device=device)\n",
    "    rays_o = rays_o_all[idx]\n",
    "    rays_d = rays_d_all[idx]\n",
    "    rays_d_unit = rays_d_all_unit[idx]\n",
    "    target = rgb_all[idx]\n",
    "\n",
    "    z_c, pts_c = sample_along_rays(rays_o, rays_d, near, far, S=S_coarse, stratified=True)\n",
    "    dirs_c = rays_d_unit[:, None, :].expand(-1, S_coarse, -1)\n",
    "    rgb_c, sigma_c = model(pts_c, dirs_c)\n",
    "    rgb_map_c, _, w_c = volume_render(rgb_c, sigma_c, z_c, rays_d, white_bkgd=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bins  = 0.5 * (z_c[:, 1:] + z_c[:, :-1])\n",
    "        w_mid = w_c[:, 1:-1, 0]\n",
    "        L = min(bins.shape[-1], w_mid.shape[-1])\n",
    "        z_f = sample_pdf(bins[:, :L].contiguous(),\n",
    "                         w_mid[:, :L].contiguous(),\n",
    "                         N_importance=S_fine,\n",
    "                         deterministic=False)\n",
    "\n",
    "    z_all, _ = torch.sort(torch.cat([z_c, z_f], dim=-1), dim=-1)\n",
    "    pts_all  = rays_o[:, None, :] + rays_d[:, None, :] * z_all[..., None]\n",
    "    dirs_all = rays_d_unit[:, None, :].expand(-1, z_all.shape[1], -1)\n",
    "    rgb_f, sigma_f = model(pts_all, dirs_all)\n",
    "    rgb_map_f, _, _ = volume_render(rgb_f, sigma_f, z_all, rays_d, white_bkgd=True)\n",
    "\n",
    "    loss_main = F.mse_loss(rgb_map_f, target)\n",
    "    loss_aux  = F.mse_loss(rgb_map_c, target)\n",
    "    loss = loss_main + 0.1 * loss_aux\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if it <= 10 or it % 50 == 0:\n",
    "        psnr_f = mse2psnr(loss_main).item()\n",
    "        psnr_c = mse2psnr(loss_aux).item()\n",
    "        npos = int(model.pe_xyz.freq_weights.gt(0.999).sum().item())\n",
    "        ndir = int(model.pe_dir.freq_weights.gt(0.999).sum().item())\n",
    "        _log(it, loss_main, loss_aux, psnr_f, psnr_c, npos, ndir)\n",
    "\n",
    "        dt = time.time() - t0\n",
    "        print(f\"Iter {it:5d}  L={loss.item():.6f}  PSNR_f={psnr_f:.2f}  PSNR_c={psnr_c:.2f}  \"\n",
    "              f\"[pos={npos}/{model.pe_xyz.num_freqs}, dir={ndir}/{model.pe_dir.num_freqs}]  ({dt:.1f}s)\")\n",
    "        t0 = time.time()\n",
    "\n",
    "    if it % test_every == 0:\n",
    "        test_loss, test_psnr = eval_fine(\n",
    "            model,\n",
    "            rays_o_eval, rays_d_eval, rays_d_eval_unit, rgb_eval,\n",
    "            near=near, far=far, S_coarse=64, S_fine=128, chunk=2048\n",
    "        )\n",
    "        hist_iter_eval.append(it)\n",
    "        hist_test_loss_f.append(test_loss)\n",
    "        hist_test_psnr_f.append(test_psnr)\n",
    "        print(f\"[TEST] iter {it:5d} | fine: L={test_loss:.6f}, PSNR={test_psnr:.2f}\")\n",
    "\n",
    "print(\"Finished training.\")\n",
    "\n",
    "# Smooth\n",
    "def _smooth(x, k=51):\n",
    "    x = pd.Series(x, dtype=float)\n",
    "    k = min(k, max(3, (len(x)//5)*2 + 1))\n",
    "    if k % 2 == 0: k += 1\n",
    "    return x.rolling(window=k, center=True, min_periods=1).mean().to_numpy()\n",
    "\n",
    "# Export logs\n",
    "df = pd.DataFrame({\n",
    "    \"iter\": hist_iter,\n",
    "    \"loss_f\": hist_loss_f,\n",
    "    \"loss_c\": hist_loss_c,\n",
    "    \"psnr_f\": hist_psnr_f,\n",
    "    \"psnr_c\": hist_psnr_c,\n",
    "    \"pos_on\": hist_pos_on,\n",
    "    \"dir_on\": hist_dir_on,\n",
    "})\n",
    "df_eval = pd.DataFrame({\n",
    "    \"iter_eval\": hist_iter_eval,\n",
    "    \"test_loss_f\": hist_test_loss_f,\n",
    "    \"test_psnr_f\": hist_test_psnr_f,\n",
    "})\n",
    "df.to_csv(\"training_metrics.csv\", index=False)\n",
    "df_eval.to_csv(\"training_metrics_eval.csv\", index=False)\n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(hist_iter, _smooth(hist_loss_f), label=\"train loss_f\")\n",
    "plt.plot(hist_iter_eval, _smooth(hist_test_loss_f), label=\"test  loss_f\")\n",
    "plt.xlabel(\"iter\"); plt.ylabel(\"MSE (fine)\"); plt.legend(); plt.tight_layout()\n",
    "plt.savefig(\"train_vs_test_loss_f.png\", dpi=200); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(hist_iter, _smooth(hist_psnr_f), label=\"train psnr_f\")\n",
    "plt.plot(hist_iter_eval, _smooth(hist_test_psnr_f), label=\"test  psnr_f\")\n",
    "plt.xlabel(\"iter\"); plt.ylabel(\"PSNR (dB)\"); plt.legend(); plt.tight_layout()\n",
    "plt.savefig(\"train_vs_test_psnr_f.png\", dpi=200); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(hist_iter, _smooth(hist_loss_f), label=\"loss_f (train)\")\n",
    "plt.plot(hist_iter, _smooth(hist_loss_c), label=\"loss_c (train)\")\n",
    "plt.xlabel(\"iter\"); plt.ylabel(\"loss\"); plt.legend(); plt.tight_layout()\n",
    "plt.savefig(\"train_loss.png\", dpi=200); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(hist_iter, _smooth(hist_psnr_f), label=\"psnr_f (train)\")\n",
    "plt.plot(hist_iter, _smooth(hist_psnr_c), label=\"psnr_c (train)\")\n",
    "plt.xlabel(\"iter\"); plt.ylabel(\"PSNR (dB)\"); plt.legend(); plt.tight_layout()\n",
    "plt.savefig(\"train_psnr.png\", dpi=200); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(hist_iter, hist_pos_on, label=\"pos_on\")\n",
    "plt.plot(hist_iter, hist_dir_on, label=\"dir_on\")\n",
    "plt.xlabel(\"iter\"); plt.ylabel(\"#active bands\"); plt.legend(); plt.tight_layout()\n",
    "plt.savefig(\"pe_active_bands.png\", dpi=200); plt.close()\n",
    "\n",
    "torch.save({\"model\": model.state_dict()}, \"nerf_tiny_pe.pt\")\n",
    "if torch.cuda.is_available():\n",
    "    peak_mem_gb = torch.cuda.max_memory_allocated() / (1024**3)\n",
    "    print(f\"Peak GPU memory: {peak_mem_gb:.2f} GB\")\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"  training_metrics.csv, training_metrics_eval.csv\")\n",
    "print(\"  train_vs_test_loss_f.png, train_vs_test_psnr_f.png\")\n",
    "print(\"  train_loss.png, train_psnr.png, pe_active_bands.png\")\n",
    "print(\"  nerf_tiny_pe.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c1c2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint to nerf_lego_pe.pt\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = \"nerf_lego_pe.pt\"\n",
    "torch.save({\n",
    "    \"model\": model.state_dict(),\n",
    "    \"H\": H, \"W\": W, \"focal\": focal,\n",
    "    \"near\": near, \"far\": far,\n",
    "}, ckpt_path)\n",
    "print(f\"Saved checkpoint to {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7c82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\77980\\AppData\\Local\\Temp\\ipykernel_63784\\3909893354.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(ckpt, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to render_example.png\n",
      "PSNR (vs test #0): 28.98 dB\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def render_single_view(\n",
    "    basedir=\"../data/nerf_synthetic/lego\",\n",
    "    ckpt=\"nerf_lego_pe.pt\",\n",
    "    split=\"test\",\n",
    "    idx=0,\n",
    "    down=2,\n",
    "    S_coarse=128,\n",
    "    S_fine=128,\n",
    "    near=2.0,\n",
    "    far=6.0,\n",
    "    chunk=8192,\n",
    "    white_bkgd=True,\n",
    "    out_path=\"render_example.png\"\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    imgs_np, poses_np, hwf, i_split = load_blender_data_raw(basedir)\n",
    "    H, W, focal = hwf\n",
    "\n",
    "    imgs_torch  = torch.from_numpy(imgs_np).float()\n",
    "    poses_torch = torch.from_numpy(poses_np).float()\n",
    "\n",
    "    # Convert RGBA to RGB (white background)\n",
    "    if imgs_torch.shape[-1] == 4:\n",
    "        rgb = imgs_torch[..., :3]\n",
    "        a   = imgs_torch[..., 3:4]\n",
    "        imgs_torch = rgb * a + (1.0 - a)\n",
    "\n",
    "    # Match training resolution\n",
    "    if down > 1:\n",
    "        imgs_chw = imgs_torch.permute(0, 3, 1, 2)\n",
    "        imgs_chw = F.interpolate(imgs_chw, size=(H // down, W // down), mode=\"area\")\n",
    "        imgs_torch = imgs_chw.permute(0, 2, 3, 1).contiguous()\n",
    "        H //= down\n",
    "        W //= down\n",
    "        focal /= down\n",
    "\n",
    "    split_map = {\"train\": 0, \"val\": 1, \"test\": 2}\n",
    "    ids = i_split[split_map[split]]\n",
    "    vid = ids[idx % len(ids)]\n",
    "\n",
    "    gt  = imgs_torch[vid]\n",
    "    c2w = poses_torch[vid].to(device)\n",
    "\n",
    "    # Load model\n",
    "    model = TinyNeRF_PE(Lx=10, Ld=4, hidden=256).to(device)\n",
    "    state = torch.load(ckpt, map_location=device)\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    model.eval()\n",
    "\n",
    "    # Rays\n",
    "    ro, rd = get_rays(H, W, focal, c2w)\n",
    "    ro = ro.reshape(-1, 3).to(device)\n",
    "    rd = rd.reshape(-1, 3).to(device)\n",
    "\n",
    "    # Rendering\n",
    "    rgb_out = []\n",
    "    for i in range(0, H * W, chunk):\n",
    "        rays_o = ro[i:i+chunk]\n",
    "        rays_d = rd[i:i+chunk]\n",
    "        dirs_norm = F.normalize(rays_d, dim=-1)\n",
    "\n",
    "        # Coarse\n",
    "        z_c, pts_c = sample_along_rays(rays_o, rays_d, near, far, S=S_coarse, stratified=False)\n",
    "        dirs_c = dirs_norm[:, None, :].expand(-1, S_coarse, -1)\n",
    "        rgb_c, sigma_c = model(pts_c, dirs_c)\n",
    "        rgb_map_c, _, w_c = volume_render(rgb_c, sigma_c, z_c, rays_d, white_bkgd=white_bkgd)\n",
    "\n",
    "        # Fine\n",
    "        bins  = 0.5 * (z_c[:, 1:] + z_c[:, :-1])\n",
    "        w_mid = w_c[:, 1:-1, 0]\n",
    "        L = min(bins.shape[-1], w_mid.shape[-1])\n",
    "\n",
    "        z_f = sample_pdf(bins[:, :L], w_mid[:, :L],\n",
    "                         N_importance=S_fine, deterministic=True)\n",
    "\n",
    "        z_all, _ = torch.sort(torch.cat([z_c, z_f], dim=-1), dim=-1)\n",
    "        pts_all  = rays_o[:, None, :] + rays_d[:, None, :] * z_all[..., None]\n",
    "        dirs_all = dirs_norm[:, None, :].expand(-1, z_all.shape[1], -1)\n",
    "\n",
    "        rgb_f, sigma_f = model(pts_all, dirs_all)\n",
    "        rgb_map_f, _, _ = volume_render(rgb_f, sigma_f, z_all, rays_d, white_bkgd=white_bkgd)\n",
    "\n",
    "        rgb_out.append(rgb_map_f.clamp(0, 1).cpu())\n",
    "\n",
    "    rgb_img = torch.cat(rgb_out, dim=0).view(H, W, 3).cpu().numpy()\n",
    "\n",
    "    import imageio.v2 as imageio\n",
    "    imageio.imwrite(out_path, (rgb_img * 255.0).astype(np.uint8))\n",
    "    print(f\"Saved to {out_path}\")\n",
    "\n",
    "    # PSNR\n",
    "    mse = F.mse_loss(torch.from_numpy(rgb_img).float(), gt.cpu()).item()\n",
    "    psnr = -10.0 * math.log10(max(mse, 1e-12))\n",
    "    print(f\"PSNR (vs {split} #{idx}): {psnr:.2f} dB\")\n",
    "\n",
    "\n",
    "# Example\n",
    "render_single_view(\n",
    "    basedir=\"../data/nerf_synthetic/lego\",\n",
    "    ckpt=\"nerf_lego_pe.pt\",\n",
    "    split=\"test\",\n",
    "    idx=0,\n",
    "    down=2,\n",
    "    out_path=\"render_example.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3238f962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved ground truth to gt_example.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import imageio.v2 as imageio\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "\n",
    "basedir = \"../data/nerf_synthetic/lego\"\n",
    "\n",
    "imgs_np, poses_np, hwf, i_split = load_blender_data_raw(basedir)\n",
    "H, W, focal = hwf\n",
    "\n",
    "imgs_torch = torch.from_numpy(imgs_np).float()\n",
    "\n",
    "# RGBA  RGB (white background)\n",
    "if imgs_torch.shape[-1] == 4:\n",
    "    rgb = imgs_torch[..., :3]\n",
    "    a   = imgs_torch[..., 3:4]\n",
    "    imgs_torch = rgb * a + (1.0 - a)\n",
    "\n",
    "# downsample (match training)\n",
    "down = 2\n",
    "if down > 1:\n",
    "    imgs_chw = imgs_torch.permute(0, 3, 1, 2)\n",
    "    imgs_chw = F.interpolate(imgs_chw, size=(H // down, W // down), mode=\"area\")\n",
    "    imgs_torch = imgs_chw.permute(0, 2, 3, 1).contiguous()\n",
    "    H //= down\n",
    "    W //= down\n",
    "    focal /= down\n",
    "\n",
    "# pick first test image\n",
    "i_test = i_split[2]\n",
    "idx = i_test[0]\n",
    "gt = imgs_torch[idx].cpu()\n",
    "\n",
    "gt_np = (gt.numpy() * 255).astype(np.uint8)\n",
    "imageio.imwrite(\"gt_example.png\", gt_np)\n",
    "\n",
    "print(\"Saved: gt_example.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0384fb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\77980\\AppData\\Local\\Temp\\ipykernel_63784\\1714371998.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(CKPT_PATH, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved  novel_pitch_up_white.png / novel_pitch_up_panel_white.png\n"
     ]
    }
   ],
   "source": [
    "import math, numpy as np, torch, imageio.v2 as imageio\n",
    "from torch.nn import functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def rodrigues(axis, theta):\n",
    "    axis = axis / (np.linalg.norm(axis) + 1e-8)\n",
    "    x, y, z = axis\n",
    "    c, s = math.cos(theta), math.sin(theta)\n",
    "    C = 1 - c\n",
    "    return np.array([\n",
    "        [c + x*x*C,     x*y*C - z*s, x*z*C + y*s],\n",
    "        [y*x*C + z*s,   c + y*y*C,   y*z*C - x*s],\n",
    "        [z*x*C - y*s,   z*y*C + x*s, c + z*z*C]\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "def orbit_pitch_keep_pose(c2w_ref, center, pitch_deg, world_up=np.array([0,1,0], np.float32)):\n",
    "    eye = c2w_ref[:3, 3].astype(np.float32)\n",
    "    R_ref = c2w_ref[:3, :3].astype(np.float32)\n",
    "    center = center.astype(np.float32)\n",
    "\n",
    "    r = eye - center\n",
    "    right = np.cross(world_up, r)\n",
    "    if np.linalg.norm(right) < 1e-6:\n",
    "        right = np.array([1, 0, 0], np.float32)\n",
    "    right = right / (np.linalg.norm(right) + 1e-8)\n",
    "\n",
    "    R_axis = rodrigues(right, math.radians(pitch_deg))\n",
    "    t_new = center + (R_axis @ r)\n",
    "    R_new = R_axis @ R_ref\n",
    "\n",
    "    out = c2w_ref.copy().astype(np.float32)\n",
    "    out[:3, :3] = R_new\n",
    "    out[:3, 3] = t_new\n",
    "    return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def render_image_whitebg(model, H, W, focal, c2w_np,\n",
    "                         near, far, n_samples=96, chunk=8192):\n",
    "    dev = next(model.parameters()).device\n",
    "    c2w = torch.from_numpy(c2w_np).to(dev).float()\n",
    "    rays_o, rays_d = get_rays(H, W, focal, c2w)\n",
    "    rays_o = rays_o.reshape(-1, 3)\n",
    "    rays_d = rays_d.reshape(-1, 3)\n",
    "\n",
    "    out_chunks = []\n",
    "    for i in range(0, H * W, chunk):\n",
    "        ro = rays_o[i:i+chunk]\n",
    "        rd = rays_d[i:i+chunk]\n",
    "        z, pts = sample_along_rays(ro, rd, near, far, S=n_samples, stratified=False)\n",
    "        dirs = rd[:, None, :].expand(-1, pts.shape[1], -1)\n",
    "        rgb, sigma = model(pts, dirs)\n",
    "        comp, _, _ = volume_render(rgb, sigma, z, rd, white_bkgd=True)\n",
    "        out_chunks.append(comp)\n",
    "\n",
    "    img = torch.cat(out_chunks, 0).view(H, W, 3).clamp(0, 1).cpu().numpy()\n",
    "    return img\n",
    "\n",
    "CKPT_PATH = \"nerf_lego_pe.pt\"\n",
    "BASEDIR = \"../data/nerf_synthetic/lego\"\n",
    "REF_IDX = 0\n",
    "PITCH_DEG = -15.0\n",
    "NEAR, FAR = 2.0, 6.0\n",
    "SAMPLES = 96\n",
    "CHUNK = 8192\n",
    "\n",
    "state = torch.load(CKPT_PATH, map_location=device)\n",
    "model = TinyNeRF_PE(Lx=10, Ld=4, hidden=256).to(device)\n",
    "model.load_state_dict(state[\"model\"])\n",
    "model.eval()\n",
    "\n",
    "if hasattr(model, \"pe_xyz\"):\n",
    "    model.pe_xyz.freq_weights.fill_(1.0)\n",
    "if hasattr(model, \"pe_dir\"):\n",
    "    model.pe_dir.freq_weights.fill_(1.0)\n",
    "\n",
    "imgs_np, poses_np, hwf, i_split = load_blender_data_raw(BASEDIR)\n",
    "H, W, focal = hwf\n",
    "\n",
    "gt_ref = imgs_np[REF_IDX][..., :3]\n",
    "c2w_ref = poses_np[REF_IDX].astype(np.float32)\n",
    "\n",
    "center = poses_np[..., :3, 3].mean(axis=0).astype(np.float32)\n",
    "c2w_top = orbit_pitch_keep_pose(c2w_ref, center, pitch_deg=PITCH_DEG)\n",
    "\n",
    "novel_white = render_image_whitebg(\n",
    "    model, H, W, focal, c2w_top,\n",
    "    near=NEAR, far=FAR,\n",
    "    n_samples=SAMPLES, chunk=CHUNK\n",
    ")\n",
    "\n",
    "pad = 40\n",
    "panel = np.ones((H, W * 2 + pad, 3), dtype=np.float32)\n",
    "panel[:, :W] = gt_ref\n",
    "panel[:, W + pad:] = novel_white\n",
    "\n",
    "imageio.imwrite(\"novel_pitch_up_white.png\",\n",
    "                (np.clip(novel_white, 0, 1) * 255).astype(np.uint8))\n",
    "imageio.imwrite(\"novel_pitch_up_panel_white.png\",\n",
    "                (np.clip(panel, 0, 1) * 255).astype(np.uint8))\n",
    "\n",
    "print(\"Saved: novel_pitch_up_white.png, novel_pitch_up_panel_white.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9154045",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def nerf_extract_mesh(\n",
    "    ckpt_path=\"nerf_lego_pe.pt\",\n",
    "    basedir=\"../data/nerf_synthetic/lego\",\n",
    "    grid_res=256,\n",
    "    sigma_thresh=None,         \n",
    "    aabb_mode=\"cams\",           \n",
    "    aabb_fixed=(-1.5, 1.5),\n",
    "    down=2,\n",
    "    chunk=65536,\n",
    "    out_ply=\"mesh_example.ply\",\n",
    "    do_preview=True\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    state = torch.load(ckpt_path, map_location=device)\n",
    "    model = TinyNeRF_PE(Lx=10, Ld=4, hidden=256).to(device)\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    model.eval()\n",
    "    if hasattr(model, \"pe_xyz\"): model.pe_xyz.freq_weights.fill_(1.0)\n",
    "    if hasattr(model, \"pe_dir\"): model.pe_dir.freq_weights.fill_(1.0)\n",
    "\n",
    "    if aabb_mode == \"cams\":\n",
    "        imgs_np, poses_np, hwf, _ = load_blender_data_raw(basedir)\n",
    "        H, W, focal = hwf\n",
    "        if down > 1:\n",
    "            H//=down; W//=down; focal/=down\n",
    "        cams = torch.from_numpy(poses_np).float()[..., :3, 3].to(device)  # [N,3]\n",
    "        aabb_min = cams.min(0).values - 1.0\n",
    "        aabb_max = cams.max(0).values + 1.0\n",
    "    else:\n",
    "        lo, hi = aabb_fixed\n",
    "        aabb_min = torch.tensor([lo, lo, lo], device=device)\n",
    "        aabb_max = torch.tensor([hi, hi, hi], device=device)\n",
    "\n",
    "    xs = torch.linspace(aabb_min[0], aabb_max[0], grid_res, device=device)\n",
    "    ys = torch.linspace(aabb_min[1], aabb_max[1], grid_res, device=device)\n",
    "    zs = torch.linspace(aabb_min[2], aabb_max[2], grid_res, device=device)\n",
    "    X, Y, Z = torch.meshgrid(xs, ys, zs, indexing=\"ij\")\n",
    "    grid = torch.stack([X, Y, Z], dim=-1).reshape(-1, 3)  \n",
    "\n",
    "    def make_dummy_dirs(n):\n",
    "        d = torch.zeros(n, 1, 3, device=device)\n",
    "        d[..., 2] = -1.0\n",
    "        return d\n",
    "\n",
    "    sigmas = []\n",
    "    for i in range(0, grid.shape[0], chunk):\n",
    "        pts  = grid[i:i+chunk].unsqueeze(1)      # [B,1,3]\n",
    "        dirs = make_dummy_dirs(pts.shape[0])     # [B,1,3]\n",
    "        _, sigma = model(pts, dirs)              \n",
    "        sigmas.append(sigma.squeeze(1).detach().cpu())\n",
    "    sigma_grid = torch.cat(sigmas, 0).view(grid_res, grid_res, grid_res).numpy()\n",
    "\n",
    "    chosen = sigma_thresh\n",
    "    if sigma_thresh is None:\n",
    "        scans = [1, 2, 4, 6, 8, 12, 16, 24, 32, 48, 64, 96, 128, 256]\n",
    "        stats = [(th, (sigma_grid > th).mean()) for th in scans]\n",
    "        if do_preview:\n",
    "            print(\"[INFO] sigma occupancy scan:\")\n",
    "            for th, occ in stats:\n",
    "                print(f\"  th={th:<3}  occupied={occ*100:5.2f}%\")\n",
    "        target = 0.01\n",
    "        chosen = min(stats, key=lambda t: abs(t[1] - target))[0]\n",
    "        print(f\"[INFO] auto-picked sigma_thresh={chosen} (target~1%)\")\n",
    "\n",
    "    from skimage.measure import marching_cubes\n",
    "    verts, faces, norms, _ = marching_cubes(sigma_grid, level=chosen)\n",
    "\n",
    "    scale = (aabb_max - aabb_min).detach().cpu().numpy() / (grid_res - 1)\n",
    "    verts_world = verts * scale + aabb_min.detach().cpu().numpy()\n",
    "\n",
    "    import trimesh\n",
    "    mesh = trimesh.Trimesh(\n",
    "        verts_world,\n",
    "        faces,\n",
    "        vertex_normals=norms,\n",
    "        process=True   \n",
    "    )\n",
    "    mesh.export(out_ply)\n",
    "    print(f\"[OK] Mesh exported  {out_ply}\")\n",
    "\n",
    "    return mesh, chosen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b365e71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\77980\\AppData\\Local\\Temp\\ipykernel_63784\\3699584978.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(ckpt_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] sigma occupancy scan:\n",
      "  th=1    occupied= 2.77%\n",
      "  th=2    occupied= 2.63%\n",
      "  th=4    occupied= 2.47%\n",
      "  th=6    occupied= 2.34%\n",
      "  th=8    occupied= 2.24%\n",
      "  th=12   occupied= 2.09%\n",
      "  th=16   occupied= 1.97%\n",
      "  th=24   occupied= 1.80%\n",
      "  th=32   occupied= 1.67%\n",
      "  th=48   occupied= 1.47%\n",
      "  th=64   occupied= 1.28%\n",
      "  th=96   occupied= 0.97%\n",
      "  th=128  occupied= 0.72%\n",
      "  th=256  occupied= 0.07%\n",
      "[INFO] auto-picked sigma_thresh=96 (target~1%)\n",
      "[OK] Mesh exported  mesh_example.ply\n"
     ]
    }
   ],
   "source": [
    "mesh, th = nerf_extract_mesh(\n",
    "    ckpt_path=\"nerf_lego_pe.pt\",\n",
    "    basedir=\"../data/nerf_synthetic/lego\",\n",
    "    aabb_mode=\"fixed\", aabb_fixed=(-1.5, 1.5),   \n",
    "    grid_res=128,\n",
    "    sigma_thresh=None,                       \n",
    "    down=2, chunk=65536, out_ply=\"mesh_example.ply\",\n",
    "    do_preview=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ccbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved  mesh_example.png\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "def save_mesh_png(ply_path=\"mesh_example.ply\", out_png=\"mesh_example.png\",\n",
    "                  w=1000, h=750, bg=[1,1,1], azim=35, elev=-15, zoom=0.85):\n",
    "    mesh = o3d.io.read_triangle_mesh(ply_path)\n",
    "    mesh.compute_vertex_normals()\n",
    "\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window(visible=False, width=w, height=h)\n",
    "    vis.add_geometry(mesh)\n",
    "\n",
    "    opt = vis.get_render_option()\n",
    "    opt.background_color = bg\n",
    "    opt.mesh_show_back_face = True\n",
    "    opt.light_on = True\n",
    "\n",
    "    ctr = vis.get_view_control()\n",
    "    ctr.change_field_of_view(step=5.0)     \n",
    "    ctr.rotate(azim, elev)                 \n",
    "    ctr.set_zoom(zoom)\n",
    "\n",
    "    vis.poll_events(); vis.update_renderer()\n",
    "    vis.capture_screen_image(out_png)\n",
    "    vis.destroy_window()\n",
    "    print(f\"[OK] saved  {out_png}\")\n",
    "\n",
    "save_mesh_png(\"mesh_example.ply\", \"mesh_example.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
